// ============================================================================
// ğŸ“ src/services/api/EnhancedChatAPI.ts
// ğŸ’¬ í–¥ìƒëœ AI ì±„íŒ… API ì„œë¹„ìŠ¤ (ë°±ì—”ë“œ ì—°ë™ ê°•í™”)
// ============================================================================

import { BackendAPIClient } from './BackendAPIClient';
import type { ChatResponse, ChatMessage, PersonalContext } from '../../types/chat.types';
import type { UnifiedAIPassport } from '../../types/passport.types';

export interface SendChatMessageRequest {
  message: string;
  model: string;
  conversationId?: string;
  userId?: string;
  passportData?: UnifiedAIPassport;
  attachments?: File[];
  voiceData?: Blob;
}

export interface SendChatMessageResponse {
  success: boolean;
  message: {
    id: string;
    conversationId: string;
    content: string;
    model: string;
    usedPassportData: string[];
    cueTokensEarned: number;
    responseTimeMs: number;
    cueExtractionStarted: boolean;
    verification: {
      verified: boolean;
      signature: string;
      biometric: boolean;
    };
  };
  personalContext: {
    cuesUsed: number;
    vaultsAccessed: number;
    personalityMatch: number;
    behaviorPatterns: string[];
    newCueExtraction: string;
  };
  user?: {
    id: string;
    username: string;
    did: string;
  };
  error?: string;
}

export interface ChatHistoryMessage {
  id: string;
  conversation_id: string;
  message_type: 'user' | 'ai';
  content: string;
  ai_model?: string;
  cue_tokens_earned?: number;
  created_at: string;
  attachments?: any[];
  verification_signature?: string;
}

export interface AvailableModel {
  id: string;
  name: string;
  available: boolean;
  recommended?: boolean;
  type: 'hybrid' | 'cloud' | 'local';
  provider?: string;
  description?: string;
  speed?: 'very-fast' | 'fast' | 'moderate' | 'slow';
}

export interface OllamaStatus {
  connected: boolean;
  url: string;
  models: string[];
  modelCount: number;
  recommendedModels: string[];
  status: 'ready' | 'disconnected' | 'error';
}

export class EnhancedChatAPI extends BackendAPIClient {
  private wsConnection: WebSocket | null = null;
  private messageQueue: any[] = [];
  private reconnectAttempts = 0;
  private maxReconnectAttempts = 5;
  private reconnectDelay = 3000;

  constructor() {
    super();
    this.initializeWebSocket();
  }

  // ============================================================================
  // ğŸ”— WebSocket ì‹¤ì‹œê°„ ì—°ê²°
  // ============================================================================

  private initializeWebSocket() {
    if (typeof window === 'undefined') return;

    try {
      const wsUrl = this.baseURL.replace('http', 'ws') + '/ws';
      console.log('ğŸ”— WebSocket ì—°ê²° ì‹œë„:', wsUrl);
      
      this.wsConnection = new WebSocket(wsUrl);
      
      this.wsConnection.onopen = () => {
        console.log('âœ… WebSocket ì—°ê²°ë¨');
        this.reconnectAttempts = 0;
        this.flushMessageQueue();
      };
      
      this.wsConnection.onmessage = (event) => {
        try {
          const data = JSON.parse(event.data);
          this.handleRealtimeMessage(data);
        } catch (error) {
          console.error('WebSocket ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜:', error);
        }
      };
      
      this.wsConnection.onclose = () => {
        console.log('âŒ WebSocket ì—°ê²° ì¢…ë£Œ');
        this.handleReconnect();
      };
      
      this.wsConnection.onerror = (error) => {
        console.error('âŒ WebSocket ì˜¤ë¥˜:', error);
      };
      
    } catch (error) {
      console.error('âŒ WebSocket ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
    }
  }

  private handleReconnect() {
    if (this.reconnectAttempts < this.maxReconnectAttempts) {
      this.reconnectAttempts++;
      console.log(`ğŸ”„ WebSocket ì¬ì—°ê²° ì‹œë„ ${this.reconnectAttempts}/${this.maxReconnectAttempts}`);
      
      setTimeout(() => {
        this.initializeWebSocket();
      }, this.reconnectDelay * this.reconnectAttempts);
    }
  }

  private flushMessageQueue() {
    while (this.messageQueue.length > 0 && this.wsConnection?.readyState === WebSocket.OPEN) {
      const message = this.messageQueue.shift();
      this.wsConnection.send(JSON.stringify(message));
    }
  }

  private handleRealtimeMessage(data: any) {
    // ì‹¤ì‹œê°„ ë©”ì‹œì§€ ì²˜ë¦¬ (CUE ë§ˆì´ë‹, AI ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë° ë“±)
    console.log('ğŸ“¨ ì‹¤ì‹œê°„ ë©”ì‹œì§€:', data);
    
    // ì´ë²¤íŠ¸ ë°œìƒ (ìƒìœ„ ì»´í¬ë„ŒíŠ¸ì—ì„œ êµ¬ë… ê°€ëŠ¥)
    window.dispatchEvent(new CustomEvent('chatRealtimeUpdate', { detail: data }));
  }

  public sendRealtimeMessage(message: any) {
    if (this.wsConnection?.readyState === WebSocket.OPEN) {
      this.wsConnection.send(JSON.stringify(message));
    } else {
      this.messageQueue.push(message);
    }
  }

  // ============================================================================
  // ğŸ’¬ í–¥ìƒëœ ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡
  // ============================================================================

  async sendChatMessage(request: SendChatMessageRequest): Promise<SendChatMessageResponse> {
    const {
      message,
      model,
      conversationId,
      userId,
      passportData,
      attachments = [],
      voiceData
    } = request;

    try {
      console.log(`ğŸ’¬ ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡: ${model} (${message.slice(0, 50)}...)`);

      // ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬
      let attachmentUrls: string[] = [];
      if (attachments.length > 0) {
        attachmentUrls = await this.uploadAttachments(attachments);
      }

      // ìŒì„± ë°ì´í„° ì²˜ë¦¬
      let voiceUrl: string | undefined;
      if (voiceData) {
        voiceUrl = await this.uploadVoiceData(voiceData);
      }

      // API ìš”ì²­ ë°ì´í„° êµ¬ì„±
      const requestData = {
        message,
        model,
        conversationId,
        userId: userId || passportData?.did,
        passportData,
        attachments: attachmentUrls,
        voiceUrl,
        timestamp: new Date().toISOString(),
        clientInfo: {
          userAgent: navigator.userAgent,
          platform: navigator.platform,
          language: navigator.language
        }
      };

      console.log('ğŸ“¤ ìš”ì²­ ë°ì´í„°:', {
        message: message.slice(0, 50),
        model,
        hasPassportData: !!passportData,
        attachmentCount: attachments.length,
        hasVoice: !!voiceData
      });

      // ë°±ì—”ë“œ API í˜¸ì¶œ
      const response = await this.post('/api/ai/chat', requestData);

      if (!response.success) {
        throw new Error(response.error || 'AI ì±„íŒ… ì‘ë‹µ ì‹¤íŒ¨');
      }

      console.log('âœ… ì±„íŒ… ì‘ë‹µ ì„±ê³µ:', {
        messageId: response.message.id,
        cueEarned: response.message.cueTokensEarned,
        responseTime: response.message.responseTimeMs
      });

      // ì‹¤ì‹œê°„ ì•Œë¦¼ ì „ì†¡
      this.sendRealtimeMessage({
        type: 'chat_complete',
        conversationId: response.message.conversationId,
        messageId: response.message.id,
        cueEarned: response.message.cueTokensEarned
      });

      return response;

    } catch (error: any) {
      console.error('ğŸ’¥ ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨:', error);
      
      // Mock ì‘ë‹µ ìƒì„± (ë°±ì—”ë“œ ì˜¤ë¥˜ ì‹œ)
      const mockResponse = this.generateMockChatResponse(message, model, passportData);
      
      // ì˜¤ë¥˜ë„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì•Œë¦¼
      this.sendRealtimeMessage({
        type: 'chat_error',
        error: error.message,
        fallbackMode: 'mock'
      });

      return mockResponse;
    }
  }

  // ============================================================================
  // ğŸ“ íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
  // ============================================================================

  private async uploadAttachments(files: File[]): Promise<string[]> {
    try {
      const formData = new FormData();
      files.forEach((file, index) => {
        formData.append(`attachment_${index}`, file);
      });

      const response = await this.postFormData('/api/upload/attachments', formData);
      return response.urls || [];

    } catch (error) {
      console.error('ì²¨ë¶€íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨:', error);
      return [];
    }
  }

  private async uploadVoiceData(voiceBlob: Blob): Promise<string> {
    try {
      const formData = new FormData();
      formData.append('voice', voiceBlob, 'voice_message.webm');

      const response = await this.postFormData('/api/upload/voice', formData);
      return response.url || '';

    } catch (error) {
      console.error('ìŒì„± ë°ì´í„° ì—…ë¡œë“œ ì‹¤íŒ¨:', error);
      return '';
    }
  }

  // ============================================================================
  // ğŸ“š ì±„íŒ… íˆìŠ¤í† ë¦¬ ì¡°íšŒ
  // ============================================================================

  async getChatHistory(
    userDid: string,
    conversationId?: string,
    limit: number = 50
  ): Promise<ChatHistoryMessage[]> {
    try {
      const endpoint = conversationId 
        ? `/api/ai/chat/history/${conversationId}?limit=${limit}`
        : `/api/ai/chat/history?limit=${limit}`;

      const response = await this.get(endpoint, {
        headers: {
          'X-User-DID': userDid
        }
      });

      return response.messages || [];

    } catch (error) {
      console.error('ì±„íŒ… íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì‹¤íŒ¨:', error);
      return this.generateMockChatHistory(userDid, conversationId);
    }
  }

  // ============================================================================
  // ğŸ¤– AI ëª¨ë¸ ê´€ë¦¬
  // ============================================================================

  async getAvailableModels(): Promise<AvailableModel[]> {
    try {
      const response = await this.get('/api/ai/models');
      return response.models || this.getDefaultModels();

    } catch (error) {
      console.warn('ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©:', error);
      return this.getDefaultModels();
    }
  }

  async getOllamaStatus(): Promise<OllamaStatus> {
    try {
      const response = await this.get('/api/ai/ollama/health');
      return response;

    } catch (error) {
      console.error('Ollama ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨:', error);
      return {
        connected: false,
        url: 'http://localhost:11434',
        models: [],
        modelCount: 0,
        recommendedModels: ['llama3.2:3b', 'llama3.2:1b'],
        status: 'error'
      };
    }
  }

  async downloadOllamaModel(modelName: string): Promise<boolean> {
    try {
      const response = await this.post('/api/ai/ollama/pull', { model: modelName });
      return response.success;

    } catch (error) {
      console.error(`Ollama ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (${modelName}):`, error);
      return false;
    }
  }

  // ============================================================================
  // ğŸ“Š ê°œì¸í™” ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ
  // ============================================================================

  async getPersonalContext(userDid: string): Promise<PersonalContext> {
    try {
      const response = await this.get('/api/ai/context', {
        headers: {
          'X-User-DID': userDid
        }
      });

      return response.context;

    } catch (error) {
      console.error('ê°œì¸í™” ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨:', error);
      return this.generateMockPersonalContext();
    }
  }

  // ============================================================================
  // ğŸ­ Mock ì‘ë‹µ ìƒì„±ê¸°ë“¤
  // ============================================================================

  private generateMockChatResponse(
    message: string,
    model: string,
    passportData?: UnifiedAIPassport
  ): SendChatMessageResponse {
    const responses = [
      `**${model}**ì„ í†µí•œ ê°œì¸í™”ëœ ì‘ë‹µì…ë‹ˆë‹¤!\n\n"${message}"ì— ëŒ€í•´ AI Passport ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ë§ì¶¤í˜• ë‹µë³€ì„ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤.`,
      `CUE Protocolì˜ **${model}** ëª¨ë¸ì´ ë‹¹ì‹ ì˜ ê°œì¸ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì í™”ëœ ì‘ë‹µì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.`,
      `**ë°±ì—”ë“œ Mock ëª¨ë“œ**: ${model} ëª¨ë¸ì„ í†µí•´ "${message}"ì— ëŒ€í•œ ì‹œë®¬ë ˆì´ì…˜ ì‘ë‹µì…ë‹ˆë‹¤.`
    ];

    return {
      success: true,
      message: {
        id: `mock_${Date.now()}`,
        conversationId: `conv_${Date.now()}`,
        content: responses[Math.floor(Math.random() * responses.length)],
        model,
        usedPassportData: passportData ? ['ì„±ê²© í”„ë¡œí•„', 'í•™ìŠµ íŒ¨í„´', 'ê°œì¸ ì„ í˜¸ë„'] : [],
        cueTokensEarned: Math.floor(Math.random() * 15) + 5,
        responseTimeMs: Math.floor(Math.random() * 2000) + 500,
        cueExtractionStarted: true,
        verification: {
          verified: true,
          signature: `mock_${Math.random().toString(36)}`,
          biometric: true
        }
      },
      personalContext: {
        cuesUsed: Math.floor(Math.random() * 10) + 1,
        vaultsAccessed: Math.floor(Math.random() * 3) + 1,
        personalityMatch: 0.85 + Math.random() * 0.15,
        behaviorPatterns: ['ì°½ì˜ì ', 'ë¶„ì„ì ', 'ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”'],
        newCueExtraction: 'processing'
      },
      user: passportData ? {
        id: passportData.did,
        username: passportData.username || 'MockUser',
        did: passportData.did
      } : undefined
    };
  }

  private generateMockChatHistory(userDid: string, conversationId?: string): ChatHistoryMessage[] {
    const messages: ChatHistoryMessage[] = [];
    const messageCount = Math.floor(Math.random() * 5) + 3;

    for (let i = 0; i < messageCount; i++) {
      const isUser = i % 2 === 0;
      messages.push({
        id: `mock_msg_${i}`,
        conversation_id: conversationId || `conv_${Date.now()}`,
        message_type: isUser ? 'user' : 'ai',
        content: isUser 
          ? `ì‚¬ìš©ì ë©”ì‹œì§€ ${i + 1}: í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ì…ë‹ˆë‹¤.`
          : `AI ì‘ë‹µ ${i + 1}: ê°œì¸í™”ëœ ë‹µë³€ì„ ì œê³µë“œë ¸ìŠµë‹ˆë‹¤.`,
        ai_model: isUser ? undefined : 'personalized-agent',
        cue_tokens_earned: isUser ? undefined : Math.floor(Math.random() * 10) + 3,
        created_at: new Date(Date.now() - (messageCount - i) * 60000).toISOString(),
        verification_signature: isUser ? undefined : `mock_sig_${i}`
      });
    }

    return messages;
  }

  private generateMockPersonalContext(): PersonalContext {
    return {
      personalityProfile: {
        type: 'INTJ-A (ë¶„ì„ì )',
        communicationStyle: 'Direct',
        learningPattern: 'Visual',
        decisionMaking: 'Analytical',
        workingStyle: 'Independent'
      },
      totalCues: Math.floor(Math.random() * 50) + 20,
      vaultsCount: Math.floor(Math.random() * 5) + 2,
      behaviorPatterns: ['í˜ì‹ ì ', 'ì²´ê³„ì ', 'ëª©í‘œì§€í–¥ì '],
      recentInteractions: Math.floor(Math.random() * 20) + 5,
      personalityMatch: 0.88 + Math.random() * 0.12,
      preferences: {
        responseLength: 'detailed',
        technicalLevel: 'advanced',
        communicationTone: 'professional'
      }
    };
  }

  private getDefaultModels(): AvailableModel[] {
    return [
      {
        id: 'personalized-agent',
        name: 'Personal Agent',
        available: true,
        recommended: true,
        type: 'hybrid',
        provider: 'CUE Protocol',
        description: 'AI Passport ê¸°ë°˜ ê°œì¸í™” ëª¨ë¸'
      },
      {
        id: 'gpt-4o',
        name: 'GPT-4o',
        available: false,
        type: 'cloud',
        provider: 'OpenAI',
        description: 'OpenAI ìµœê³  ì„±ëŠ¥ ëª¨ë¸'
      },
      {
        id: 'claude-3.5-sonnet',
        name: 'Claude 3.5 Sonnet',
        available: false,
        type: 'cloud',
        provider: 'Anthropic',
        description: 'Anthropic ê³ í’ˆì§ˆ ëª¨ë¸'
      }
    ];
  }

  // ============================================================================
  // ğŸ§¹ ì •ë¦¬
  // ============================================================================

  public cleanup() {
    if (this.wsConnection) {
      this.wsConnection.close();
      this.wsConnection = null;
    }
    this.messageQueue = [];
    this.reconnectAttempts = 0;
  }
}
// ============================================================================
// ğŸ¦™ Ollama ì„œë¹„ìŠ¤ - ë¡œì»¬ AI ëª¨ë¸ ê´€ë¦¬
// íŒŒì¼: backend/src/services/ollama.ts
// ì—­í• : Ollama ë¡œì»¬ AI ëª¨ë¸ ì—°ë™ ë° ê´€ë¦¬
// ============================================================================

interface OllamaMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

interface OllamaResponse {
  model: string;
  response: string;
  done: boolean;
  total_duration?: number;
  load_duration?: number;
  prompt_eval_count?: number;
  prompt_eval_duration?: number;
  eval_count?: number;
  eval_duration?: number;
}

class OllamaService {
  private baseUrl: string;
  private isConnected: boolean = false;
  private availableModels: string[] = [];
  private lastCheck: number = 0;
  private checkInterval: number = 5 * 60 * 1000; // 5ë¶„

  constructor() {
    this.baseUrl = process.env.OLLAMA_URL || 'http://localhost:11434';
    console.log(`ğŸ¦™ Ollama ì„œë¹„ìŠ¤ ì´ˆê¸°í™” - URL: ${this.baseUrl}`);
  }

  // ============================================================================
  // ğŸ” Ollama ì—°ê²° ìƒíƒœ í™•ì¸
  // ============================================================================

  public async checkConnection(): Promise<boolean> {
    const now = Date.now();
    
    // ìºì‹œëœ ê²°ê³¼ ì‚¬ìš© (5ë¶„ ì´ë‚´)
    if (now - this.lastCheck < this.checkInterval && this.lastCheck > 0) {
      return this.isConnected;
    }

    try {
      console.log('ğŸ” Ollama ì—°ê²° ìƒíƒœ í™•ì¸ ì¤‘...');
      
      const response = await fetch(`${this.baseUrl}/api/version`, {
        method: 'GET',
        timeout: 5000 // 5ì´ˆ íƒ€ì„ì•„ì›ƒ
      } as any);

      if (response.ok) {
        const version = await response.json();
        console.log(`âœ… Ollama ì—°ê²° ì„±ê³µ - ë²„ì „: ${version.version || 'unknown'}`);
        this.isConnected = true;
      } else {
        console.log('âŒ Ollama ì‘ë‹µ ì˜¤ë¥˜:', response.status);
        this.isConnected = false;
      }
    } catch (error: any) {
      console.log('âŒ Ollama ì—°ê²° ì‹¤íŒ¨:', error.message);
      this.isConnected = false;
    }

    this.lastCheck = now;
    return this.isConnected;
  }

  // ============================================================================
  // ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
  // ============================================================================

  public async getModels(): Promise<string[]> {
    try {
      console.log('ğŸ“‹ Ollama ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì¤‘...');
      
      const response = await fetch(`${this.baseUrl}/api/tags`, {
        method: 'GET',
        timeout: 10000
      } as any);

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }

      const data = await response.json();
      const models = data.models?.map((model: any) => model.name) || [];
      
      this.availableModels = models;
      console.log(`âœ… Ollama ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì„±ê³µ - ${models.length}ê°œ ëª¨ë¸`);
      console.log('ğŸ”¹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:', models.join(', '));
      
      return models;
    } catch (error: any) {
      console.error('âŒ Ollama ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', error.message);
      return [];
    }
  }

  // ============================================================================
  // ğŸ¤– ì±„íŒ… ì‘ë‹µ ìƒì„±
  // ============================================================================

  public async chat(
    model: string, 
    messages: OllamaMessage[], 
    stream: boolean = false
  ): Promise<string> {
    try {
      console.log(`ğŸ¤– Ollama ì±„íŒ… ìš”ì²­ - ëª¨ë¸: ${model}, ë©”ì‹œì§€: ${messages.length}ê°œ`);

      const isConnected = await this.checkConnection();
      if (!isConnected) {
        throw new Error('Ollama is not connected');
      }

      const requestBody = {
        model: model,
        messages: messages,
        stream: stream,
        options: {
          temperature: 0.7,
          top_p: 0.9,
          top_k: 40,
          repeat_penalty: 1.1
        }
      };

      const response = await fetch(`${this.baseUrl}/api/chat`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify(requestBody),
        timeout: 60000 // 60ì´ˆ íƒ€ì„ì•„ì›ƒ
      } as any);

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`HTTP ${response.status}: ${errorText}`);
      }

      if (stream) {
        // ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
        return await this.handleStreamResponse(response);
      } else {
        // ì¼ë°˜ ì‘ë‹µ ì²˜ë¦¬
        const data: OllamaResponse = await response.json();
        console.log(`âœ… Ollama ì‘ë‹µ ìƒì„± ì™„ë£Œ - ê¸¸ì´: ${data.response?.length || 0}ì`);
        return data.response || '';
      }

    } catch (error: any) {
      console.error(`âŒ Ollama ì±„íŒ… ì˜¤ë¥˜ (${model}):`, error.message);
      throw new Error(`Ollama chat failed: ${error.message}`);
    }
  }

  // ============================================================================
  // ğŸ”½ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
  // ============================================================================

  public async pullModel(modelName: string): Promise<void> {
    try {
      console.log(`ğŸ”½ Ollama ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘ - ${modelName}`);

      const response = await fetch(`${this.baseUrl}/api/pull`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          name: modelName,
          stream: false
        })
      } as any);

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`HTTP ${response.status}: ${errorText}`);
      }

      console.log(`âœ… Ollama ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘ë¨ - ${modelName}`);
      
      // ëª¨ë¸ ëª©ë¡ ìºì‹œ ë¬´íš¨í™”
      this.availableModels = [];
      this.lastCheck = 0;

    } catch (error: any) {
      console.error(`âŒ Ollama ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (${modelName}):`, error.message);
      throw error;
    }
  }

  // ============================================================================
  // ğŸ“Š ëª¨ë¸ ì •ë³´ ì¡°íšŒ
  // ============================================================================

  public async getModelInfo(modelName: string): Promise<any> {
    try {
      console.log(`ğŸ“Š Ollama ëª¨ë¸ ì •ë³´ ì¡°íšŒ - ${modelName}`);

      const response = await fetch(`${this.baseUrl}/api/show`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          name: modelName
        })
      } as any);

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }

      const modelInfo = await response.json();
      console.log(`âœ… ëª¨ë¸ ì •ë³´ ì¡°íšŒ ì„±ê³µ - ${modelName}`);
      
      return {
        name: modelInfo.name,
        size: modelInfo.size,
        digest: modelInfo.digest,
        modified: modelInfo.modified_at,
        parameters: modelInfo.parameters,
        template: modelInfo.template,
        details: modelInfo.details
      };

    } catch (error: any) {
      console.error(`âŒ ëª¨ë¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ (${modelName}):`, error.message);
      throw error;
    }
  }

  // ============================================================================
  // ğŸ—‘ï¸ ëª¨ë¸ ì‚­ì œ
  // ============================================================================

  public async deleteModel(modelName: string): Promise<void> {
    try {
      console.log(`ğŸ—‘ï¸ Ollama ëª¨ë¸ ì‚­ì œ - ${modelName}`);

      const response = await fetch(`${this.baseUrl}/api/delete`, {
        method: 'DELETE',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          name: modelName
        })
      } as any);

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }

      console.log(`âœ… ëª¨ë¸ ì‚­ì œ ì™„ë£Œ - ${modelName}`);
      
      // ëª¨ë¸ ëª©ë¡ ìºì‹œ ë¬´íš¨í™”
      this.availableModels = this.availableModels.filter(m => m !== modelName);

    } catch (error: any) {
      console.error(`âŒ ëª¨ë¸ ì‚­ì œ ì‹¤íŒ¨ (${modelName}):`, error.message);
      throw error;
    }
  }

  // ============================================================================
  // ğŸ”§ ì¼ë°˜ ìƒì„± (ë ˆê±°ì‹œ ì§€ì›)
  // ============================================================================

  public async generate(
    model: string, 
    prompt: string, 
    stream: boolean = false
  ): Promise<string> {
    try {
      console.log(`ğŸ”§ Ollama í…ìŠ¤íŠ¸ ìƒì„± - ëª¨ë¸: ${model}`);

      const requestBody = {
        model: model,
        prompt: prompt,
        stream: stream,
        options: {
          temperature: 0.7,
          top_p: 0.9,
          top_k: 40
        }
      };

      const response = await fetch(`${this.baseUrl}/api/generate`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify(requestBody),
        timeout: 60000
      } as any);

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }

      if (stream) {
        return await this.handleStreamResponse(response);
      } else {
        const data = await response.json();
        return data.response || '';
      }

    } catch (error: any) {
      console.error(`âŒ Ollama í…ìŠ¤íŠ¸ ìƒì„± ì˜¤ë¥˜:`, error.message);
      throw error;
    }
  }

  // ============================================================================
  // ğŸ› ï¸ í”„ë¼ì´ë¹— í—¬í¼ ë©”ì„œë“œë“¤
  // ============================================================================

  private async handleStreamResponse(response: Response): Promise<string> {
    const reader = response.body?.getReader();
    if (!reader) {
      throw new Error('ìŠ¤íŠ¸ë¦¼ ì‘ë‹µì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
    }

    let fullResponse = '';
    const decoder = new TextDecoder();

    try {
      while (true) {
        const { done, value } = await reader.read();
        
        if (done) break;

        const chunk = decoder.decode(value, { stream: true });
        const lines = chunk.split('\n').filter(line => line.trim());

        for (const line of lines) {
          try {
            const data = JSON.parse(line);
            if (data.response) {
              fullResponse += data.response;
            }
            if (data.done) {
              return fullResponse;
            }
          } catch (parseError) {
            // JSON íŒŒì‹± ì˜¤ë¥˜ ë¬´ì‹œ (ë¶€ë¶„ ì‘ë‹µì¼ ìˆ˜ ìˆìŒ)
          }
        }
      }

      return fullResponse;
    } finally {
      reader.releaseLock();
    }
  }

  // ============================================================================
  // ğŸ“Š ê³µê°œ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
  // ============================================================================

  public getConnectionStatus(): {
    connected: boolean;
    url: string;
    lastCheck: string;
    modelCount: number;
  } {
    return {
      connected: this.isConnected,
      url: this.baseUrl,
      lastCheck: new Date(this.lastCheck).toISOString(),
      modelCount: this.availableModels.length
    };
  }

  public getCachedModels(): string[] {
    return [...this.availableModels];
  }

  public getRecommendedModels(): Array<{
    name: string;
    size: string;
    description: string;
    recommended: boolean;
  }> {
    return [
      {
        name: 'llama3.2:1b',
        size: '1.3GB',
        description: 'ê°€ì¥ ë¹ ë¥¸ ì†Œí˜• ëª¨ë¸ - ì¼ë°˜ ëŒ€í™”ìš©',
        recommended: true
      },
      {
        name: 'llama3.2:3b',
        size: '2.0GB',
        description: 'ê· í˜•ì¡íŒ ì„±ëŠ¥ê³¼ ì†ë„ - ê¶Œì¥ ëª¨ë¸',
        recommended: true
      },
      {
        name: 'gemma2:2b',
        size: '1.6GB',
        description: 'Google ê¸°ë°˜ íš¨ìœ¨ì  ëª¨ë¸',
        recommended: false
      },
      {
        name: 'qwen2.5:3b',
        size: '1.9GB',
        description: 'ë‹¤êµ­ì–´ ì§€ì› ìš°ìˆ˜ ëª¨ë¸',
        recommended: false
      },
      {
        name: 'llama3.1:8b',
        size: '4.7GB',
        description: 'ê³ ì„±ëŠ¥ ëŒ€í˜• ëª¨ë¸ - ê³ ê¸‰ ì‘ì—…ìš©',
        recommended: false
      }
    ];
  }

  public async healthCheck(): Promise<{
    status: string;
    connected: boolean;
    models: number;
    version?: string;
    error?: string;
  }> {
    try {
      const isConnected = await this.checkConnection();
      
      if (!isConnected) {
        return {
          status: 'disconnected',
          connected: false,
          models: 0,
          error: 'Ollama service is not available'
        };
      }

      const models = await this.getModels();
      
      return {
        status: 'healthy',
        connected: true,
        models: models.length,
        version: 'unknown' // ë²„ì „ ì •ë³´ëŠ” ë³„ë„ APIë¡œ ì¡°íšŒ ê°€ëŠ¥
      };

    } catch (error: any) {
      return {
        status: 'error',
        connected: false,
        models: 0,
        error: error.message
      };
    }
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° export
export const ollamaService = new OllamaService();

// í´ë˜ìŠ¤ë„ export (í…ŒìŠ¤íŠ¸ìš©)
export { OllamaService };
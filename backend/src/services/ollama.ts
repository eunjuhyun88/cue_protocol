// ============================================================================
// ğŸ¦™ backend/src/services/ollama.ts
// ğŸ”§ Ollama ì—°ê²° ë¬¸ì œ í•´ê²° ë° ì•ˆì •ì„± ê°œì„  (ì™„ì „ ë¦¬íŒ©í† ë§)
// ============================================================================

interface OllamaMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

interface OllamaResponse {
  model: string;
  created_at: string;
  response?: string;
  message?: {
    role: string;
    content: string;
  };
  done: boolean;
  context?: number[];
  total_duration?: number;
  load_duration?: number;
  prompt_eval_count?: number;
  prompt_eval_duration?: number;
  eval_count?: number;
  eval_duration?: number;
}

interface OllamaError {
  error: string;
  code?: string;
}

interface OllamaModel {
  name: string;
  size: number;
  digest: string;
  modified_at: string;
}

/**
 * Ollama ì„œë¹„ìŠ¤ - ì™„ì „íˆ ê°œì„ ëœ ë²„ì „
 * ì—°ê²° ì•ˆì •ì„±, ì¬ì‹œë„ ë¡œì§, ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
 */
export class OllamaService {
  private static instance: OllamaService;
  private baseUrl: string;
  private timeout: number;
  private retryCount: number;
  private isAvailable: boolean = false;
  private lastHealthCheck: number = 0;
  private healthCheckInterval: number = 5 * 60 * 1000; // 5ë¶„
  private models: string[] = [];
  private modelsLastFetched: number = 0;
  private modelsRefreshInterval: number = 10 * 60 * 1000; // 10ë¶„

  private constructor() {
    this.baseUrl = process.env.OLLAMA_HOST || process.env.OLLAMA_URL || 'http://localhost:11434';
    this.timeout = parseInt(process.env.OLLAMA_TIMEOUT || '60000');
    this.retryCount = parseInt(process.env.OLLAMA_RETRY_COUNT || '3');
    
    console.log('ğŸ¤– Ollama Service ì´ˆê¸°í™”:', {
      baseUrl: this.baseUrl,
      timeout: this.timeout,
      retryCount: this.retryCount
    });

    // ì´ˆê¸° í—¬ìŠ¤ì²´í¬ (ë¹„ë™ê¸°ë¡œ ì‹¤í–‰)
    this.initializeConnection();
  }

  public static getInstance(): OllamaService {
    if (!OllamaService.instance) {
      OllamaService.instance = new OllamaService();
    }
    return OllamaService.instance;
  }

  // ============================================================================
  // ğŸš€ ì´ˆê¸°í™” ë° ì—°ê²° ê´€ë¦¬
  // ============================================================================

  /**
   * ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ë° ì—°ê²° í™•ì¸
   */
  private async initializeConnection(): Promise<void> {
    try {
      console.log('ğŸ” Ollama ì´ˆê¸° ì—°ê²° í™•ì¸ ì¤‘...');
      
      const isConnected = await this.checkConnection();
      if (isConnected) {
        console.log('âœ… Ollama ì´ˆê¸° ì—°ê²° ì„±ê³µ');
        await this.refreshModels();
      } else {
        console.warn('âš ï¸ Ollama ì´ˆê¸° ì—°ê²° ì‹¤íŒ¨ - ë‚˜ì¤‘ì— ìë™ ì¬ì‹œë„ë©ë‹ˆë‹¤');
        this.printConnectionHelp();
      }
    } catch (error: any) {
      console.warn('âš ï¸ Ollama ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜:', error.message);
      this.printConnectionHelp();
    }
  }

  /**
   * ì—°ê²° ë„ì›€ë§ ì¶œë ¥
   */
  private printConnectionHelp(): void {
    console.log('\nğŸ’¡ Ollama ì„¤ì • ë„ì›€ë§:');
    console.log('1. Ollama ì„¤ì¹˜: brew install ollama');
    console.log('2. ì„œë²„ ì‹œì‘: ollama serve');
    console.log('3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: ollama pull llama3.2:3b');
    console.log('4. ëª¨ë¸ í™•ì¸: ollama list');
    console.log(`5. ì—°ê²° í™•ì¸: curl ${this.baseUrl}/api/tags\n`);
  }

  // ============================================================================
  // ğŸ” í—¬ìŠ¤ì²´í¬ ë° ì—°ê²° ìƒíƒœ ê´€ë¦¬
  // ============================================================================

  /**
   * Ollama ì„œë¹„ìŠ¤ í—¬ìŠ¤ì²´í¬ (í–¥ìƒëœ ë¡œì§)
   */
  async checkConnection(): Promise<boolean> {
    const now = Date.now();
    
    // ìµœê·¼ì— ì²´í¬í–ˆìœ¼ë©´ ìºì‹œëœ ê²°ê³¼ ì‚¬ìš© (ì„±ê³µí•œ ê²½ìš°ë§Œ)
    if (now - this.lastHealthCheck < this.healthCheckInterval && this.isAvailable) {
      return this.isAvailable;
    }

    try {
      console.log('ğŸ” Ollama í—¬ìŠ¤ì²´í¬ ì‹œì‘...');
      
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 5000); // 5ì´ˆ íƒ€ì„ì•„ì›ƒ

      const response = await fetch(`${this.baseUrl}/api/tags`, {
        method: 'GET',
        headers: {
          'Content-Type': 'application/json',
        },
        signal: controller.signal
      });

      clearTimeout(timeoutId);

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const data = await response.json();
      this.isAvailable = true;
      this.lastHealthCheck = now;
      
      console.log('âœ… Ollama ì—°ê²° ì„±ê³µ:', {
        modelCount: data.models?.length || 0,
        availableModels: data.models?.slice(0, 3).map((m: any) => m.name) || []
      });
      
      return true;

    } catch (error: any) {
      this.isAvailable = false;
      this.lastHealthCheck = now;
      
      if (error.name === 'AbortError') {
        console.error('âŒ Ollama ì—°ê²° íƒ€ì„ì•„ì›ƒ (5ì´ˆ)');
      } else if (error.code === 'ECONNREFUSED') {
        console.error('âŒ Ollama ì„œë²„ ì—°ê²° ê±°ë¶€ - ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”');
      } else {
        console.error('âŒ Ollama í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨:', error.message);
      }
      
      return false;
    }
  }

  /**
   * ê°•ì œ í—¬ìŠ¤ì²´í¬ (ìºì‹œ ë¬´ì‹œ)
   */
  async forceHealthCheck(): Promise<boolean> {
    this.lastHealthCheck = 0; // ìºì‹œ ë¬´íš¨í™”
    return await this.checkConnection();
  }

  // ============================================================================
  // ğŸ“‹ ëª¨ë¸ ê´€ë¦¬
  // ============================================================================

  /**
   * ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ (ìºì‹± ì ìš©)
   */
  async getModels(): Promise<string[]> {
    const now = Date.now();
    
    // ìºì‹œëœ ëª¨ë¸ ëª©ë¡ì´ ìˆê³  ìµœì‹ ì´ë©´ ë°˜í™˜
    if (this.models.length > 0 && now - this.modelsLastFetched < this.modelsRefreshInterval) {
      return this.models;
    }

    try {
      if (!await this.checkConnection()) {
        console.warn('âš ï¸ Ollama ì„œë¹„ìŠ¤ ì´ìš© ë¶ˆê°€ - ë¹ˆ ëª¨ë¸ ëª©ë¡ ë°˜í™˜');
        return [];
      }

      const response = await fetch(`${this.baseUrl}/api/tags`, {
        method: 'GET',
        headers: { 'Content-Type': 'application/json' },
        signal: AbortSignal.timeout(10000) // 10ì´ˆ íƒ€ì„ì•„ì›ƒ
      });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const data = await response.json();
      this.models = data.models?.map((model: OllamaModel) => model.name) || [];
      this.modelsLastFetched = now;
      
      console.log('ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ Ollama ëª¨ë¸ ì—…ë°ì´íŠ¸:', this.models);
      return this.models;

    } catch (error: any) {
      console.error('âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', error.message);
      return this.models; // ì´ì „ ìºì‹œëœ ëª©ë¡ ë°˜í™˜
    }
  }

  /**
   * ëª¨ë¸ ëª©ë¡ ê°•ì œ ìƒˆë¡œê³ ì¹¨
   */
  async refreshModels(): Promise<string[]> {
    this.modelsLastFetched = 0; // ìºì‹œ ë¬´íš¨í™”
    return await this.getModels();
  }

  /**
   * íŠ¹ì • ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
   */
  async isModelAvailable(modelName: string): Promise<boolean> {
    const models = await this.getModels();
    return models.includes(modelName);
  }

  /**
   * ì¶”ì²œ ëª¨ë¸ ëª©ë¡ ë°˜í™˜
   */
  getRecommendedModels(): Array<{name: string, size: string, description: string}> {
    return [
      {
        name: 'llama3.2:3b',
        size: '2.0GB',
        description: 'ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ ëŒ€í™”í˜• ëª¨ë¸ (ì¶”ì²œ)'
      },
      {
        name: 'llama3.2:1b',
        size: '1.3GB',
        description: 'ë§¤ìš° ë¹ ë¥¸ ê²½ëŸ‰ ëª¨ë¸'
      },
      {
        name: 'llama3.1:8b',
        size: '4.7GB',
        description: 'ê³ ì„±ëŠ¥ ëª¨ë¸ (ë” ë§ì€ ìì› í•„ìš”)'
      },
      {
        name: 'gemma2:2b',
        size: '1.6GB',
        description: 'Googleì˜ ê²½ëŸ‰ ëª¨ë¸'
      }
    ];
  }

  // ============================================================================
  // ğŸ’¬ ì±„íŒ… ê¸°ëŠ¥ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
  // ============================================================================

  /**
   * ì±„íŒ… ì™„ë£Œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
   */
  async chatCompletion(
    model: string,
    messages: OllamaMessage[],
    options: {
      temperature?: number;
      stream?: boolean;
      personalizedContext?: any;
    } = {}
  ): Promise<string> {
    
    for (let attempt = 1; attempt <= this.retryCount; attempt++) {
      try {
        console.log(`ğŸ¦™ Ollama ì±„íŒ… ì‹œë„ ${attempt}/${this.retryCount} - ëª¨ë¸: ${model}`);
        
        // ì—°ê²° í™•ì¸
        if (!await this.checkConnection()) {
          throw new Error('Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
        }

        // ëª¨ë¸ í™•ì¸
        if (!await this.isModelAvailable(model)) {
          throw new Error(`ëª¨ë¸ '${model}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.`);
        }

        const result = await this.performChatRequest(model, messages, options);
        
        console.log(`âœ… Ollama ì±„íŒ… ì„±ê³µ (ì‹œë„ ${attempt})`);
        return result;

      } catch (error: any) {
        console.error(`âŒ Ollama ì±„íŒ… ì‹œë„ ${attempt} ì‹¤íŒ¨:`, error.message);
        
        if (attempt === this.retryCount) {
          throw error; // ë§ˆì§€ë§‰ ì‹œë„ë„ ì‹¤íŒ¨í•˜ë©´ ì—ëŸ¬ ë˜ì§
        }
        
        // ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸°
        await this.delay(1000 * attempt);
      }
    }

    throw new Error('ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨');
  }

  /**
   * ì‹¤ì œ ì±„íŒ… ìš”ì²­ ìˆ˜í–‰
   */
  private async performChatRequest(
    model: string,
    messages: OllamaMessage[],
    options: {
      temperature?: number;
      stream?: boolean;
      personalizedContext?: any;
    }
  ): Promise<string> {
    
    const { temperature = 0.7, stream = false, personalizedContext } = options;

    // ë©”ì‹œì§€ë¥¼ Ollama í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    const requestBody = {
      model,
      messages: this.formatMessages(messages, personalizedContext),
      stream,
      options: {
        temperature,
        num_predict: 2000,
        top_k: 40,
        top_p: 0.9,
        repeat_penalty: 1.1
      }
    };

    console.log('ğŸ“¤ Ollama ìš”ì²­ ì „ì†¡:', {
      model,
      messageCount: messages.length,
      temperature,
      stream
    });

    const response = await fetch(`${this.baseUrl}/api/chat`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(requestBody),
      signal: AbortSignal.timeout(this.timeout)
    });

    if (!response.ok) {
      const errorText = await response.text();
      let errorMessage = `HTTP ${response.status}: ${response.statusText}`;
      
      try {
        const errorJson = JSON.parse(errorText);
        errorMessage = errorJson.error || errorMessage;
      } catch {
        // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì—ëŸ¬ ë©”ì‹œì§€ ì‚¬ìš©
      }
      
      throw new Error(errorMessage);
    }

    const data: OllamaResponse = await response.json();
    
    if (!data.done) {
      throw new Error('Ollama ì‘ë‹µì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
    }

    const content = data.message?.content || data.response || '';
    
    if (!content.trim()) {
      throw new Error('Ollamaì—ì„œ ë¹ˆ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤');
    }

    return content;
  }

  /**
   * âœ… ê°„ë‹¨í•œ generate ë°©ì‹ (ê¸°ì¡´ app.tsì™€ í˜¸í™˜)
   */
  async generate(
    model: string,
    prompt: string,
    options: {
      temperature?: number;
      num_predict?: number;
    } = {}
  ): Promise<string> {
    
    try {
      console.log(`ğŸ¦™ Ollama Generate ìš”ì²­: ${model}`);
      
      // ì—°ê²° í™•ì¸
      if (!await this.checkConnection()) {
        throw new Error('Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
      }

      const requestBody = {
        model,
        prompt,
        stream: false,
        options: {
          temperature: options.temperature || 0.7,
          num_predict: options.num_predict || 1000
        }
      };

      const response = await fetch(`${this.baseUrl}/api/generate`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(requestBody),
        signal: AbortSignal.timeout(this.timeout)
      });

      if (!response.ok) {
        throw new Error(`Ollama API HTTP ${response.status}: ${response.statusText}`);
      }

      const data = await response.json();
      const result = data.response || 'ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
      
      console.log('âœ… Ollama Generate ì„±ê³µ');
      return result;

    } catch (error: any) {
      console.error('âŒ Ollama Generate ì‹¤íŒ¨:', error.message);
      throw error;
    }
  }

  // ============================================================================
  // ğŸ› ï¸ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
  // ============================================================================

  /**
   * ë©”ì‹œì§€ë¥¼ Ollama í˜•ì‹ìœ¼ë¡œ í¬ë§·
   */
  private formatMessages(
    messages: OllamaMessage[],
    personalizedContext?: any
  ): OllamaMessage[] {
    
    const formattedMessages: OllamaMessage[] = [];

    // ê°œì¸í™” ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì‹œìŠ¤í…œ ë©”ì‹œì§€ì— ì¶”ê°€
    if (personalizedContext) {
      const contextSystemMessage: OllamaMessage = {
        role: 'system',
        content: this.formatPersonalizedContext(personalizedContext)
      };
      formattedMessages.push(contextSystemMessage);
    }

    // ê¸°ì¡´ ë©”ì‹œì§€ë“¤ ì¶”ê°€
    formattedMessages.push(...messages);

    return formattedMessages;
  }

  /**
   * ê°œì¸í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ í¬ë§·
   */
  private formatPersonalizedContext(context: any): string {
    if (!context || Object.keys(context).length === 0) {
      return 'ë‹¹ì‹ ì€ CUE Protocolì˜ ê°œì¸í™”ëœ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í•œêµ­ì–´ ì‘ë‹µì„ ì œê³µí•´ì£¼ì„¸ìš”.';
    }

    let contextPrompt = 'ë‹¹ì‹ ì€ CUE Protocolì˜ ê°œì¸í™”ëœ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n\n';
    contextPrompt += 'ì‚¬ìš©ìì— ëŒ€í•œ ì •ë³´:\n';

    if (context.personalityProfile) {
      contextPrompt += `- ì„±ê²©: ${context.personalityProfile.type || 'Adaptive'}\n`;
      contextPrompt += `- ì†Œí†µ ìŠ¤íƒ€ì¼: ${context.personalityProfile.communicationStyle || 'Balanced'}\n`;
    }

    if (context.behaviorPatterns && context.behaviorPatterns.length > 0) {
      contextPrompt += `- ê´€ì‹¬ì‚¬: ${context.behaviorPatterns.slice(0, 3).join(', ')}\n`;
    }

    if (context.preferences && Object.keys(context.preferences).length > 0) {
      contextPrompt += `- ì„ í˜¸ë„: ${context.preferences.language || 'adaptive'} ì–¸ì–´\n`;
    }

    contextPrompt += '\nì‚¬ìš©ìì˜ ì„±ê²©ê³¼ ì„ í˜¸ë„ì— ë§ì¶° ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í•œêµ­ì–´ ì‘ë‹µì„ ì œê³µí•´ì£¼ì„¸ìš”.\n';
    
    return contextPrompt;
  }

  /**
   * í´ë°± ì‘ë‹µ ìƒì„± (Ollama ì—°ê²° ì‹¤íŒ¨ ì‹œ)
   */
  getFallbackResponse(userMessage: string): string {
    console.log('ğŸ”„ í´ë°± ì‘ë‹µ ìƒì„± ì¤‘...');

    const lowerMessage = userMessage.toLowerCase();

    if (lowerMessage.includes('hello') || lowerMessage.includes('ì•ˆë…•')) {
      return 'ì•ˆë…•í•˜ì„¸ìš”! í˜„ì¬ ë¡œì»¬ AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ìˆì§€ë§Œ, ë„ì›€ì„ ë“œë¦¬ê¸° ìœ„í•´ ë…¸ë ¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.';
    }

    if (lowerMessage.includes('help') || lowerMessage.includes('ë„ì›€')) {
      return 'ë„ì›€ì´ í•„ìš”í•˜ì‹œëŠ”êµ°ìš”. í˜„ì¬ Ollama AI ì„œë¹„ìŠ¤ê°€ ì¼ì‹œì ìœ¼ë¡œ ì´ìš© ë¶ˆê°€í•˜ì§€ë§Œ, ì„œë¹„ìŠ¤ê°€ ë³µêµ¬ë˜ë©´ ë” ë‚˜ì€ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.';
    }

    if (lowerMessage.includes('error') || lowerMessage.includes('ì˜¤ë¥˜') || lowerMessage.includes('ë¬¸ì œ')) {
      return 'í˜„ì¬ Ollama AI ì‹œìŠ¤í…œì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. `ollama serve` ëª…ë ¹ì–´ë¡œ ì„œë²„ë¥¼ ì‹œì‘í•˜ê±°ë‚˜ `ollama pull llama3.2:3b` ëª…ë ¹ì–´ë¡œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•´ ë³´ì„¸ìš”.';
    }

    return `ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ Ollama AI ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\nğŸ’¡ í•´ê²° ë°©ë²•:\n1. \`ollama serve\` ëª…ë ¹ì–´ë¡œ ì„œë²„ ì‹œì‘\n2. \`ollama pull llama3.2:3b\` ëª…ë ¹ì–´ë¡œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ\n3. ì„¤ì¹˜ê°€ í•„ìš”í•œ ê²½ìš°: \`brew install ollama\`\n\nì§ˆë¬¸ "${userMessage}"ì— ëŒ€í•œ ë‹µë³€ì€ ì„œë¹„ìŠ¤ ë³µêµ¬ í›„ ì œê³µí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.`;
  }

  /**
   * ì§€ì—° í•¨ìˆ˜
   */
  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  // ============================================================================
  // ğŸ“Š ìƒíƒœ ë° ì •ë³´ ë©”ì„œë“œë“¤
  // ============================================================================

  /**
   * ì„œë¹„ìŠ¤ ìƒíƒœ ì •ë³´ ë°˜í™˜
   */
  getStatus(): {
    available: boolean;
    baseUrl: string;
    lastHealthCheck: Date | null;
    timeout: number;
    retryCount: number;
    modelCount: number;
    cachedModels: string[];
  } {
    return {
      available: this.isAvailable,
      baseUrl: this.baseUrl,
      lastHealthCheck: this.lastHealthCheck ? new Date(this.lastHealthCheck) : null,
      timeout: this.timeout,
      retryCount: this.retryCount,
      modelCount: this.models.length,
      cachedModels: this.models
    };
  }

  /**
   * ìƒì„¸ ìƒíƒœ ì •ë³´ ë°˜í™˜
   */
  async getDetailedStatus(): Promise<{
    connection: any;
    models: any;
    recommendations: any;
    troubleshooting: any;
  }> {
    const isConnected = await this.forceHealthCheck();
    const models = isConnected ? await this.refreshModels() : [];
    
    return {
      connection: {
        available: isConnected,
        baseUrl: this.baseUrl,
        lastCheck: new Date(this.lastHealthCheck).toISOString(),
        timeout: this.timeout
      },
      models: {
        available: models,
        count: models.length,
        recommended: this.getRecommendedModels(),
        lastFetched: new Date(this.modelsLastFetched).toISOString()
      },
      recommendations: {
        preferredModel: 'llama3.2:3b',
        minModel: 'llama3.2:1b',
        setupCommands: [
          'brew install ollama',
          'ollama serve',
          'ollama pull llama3.2:3b'
        ]
      },
      troubleshooting: {
        connectionCheck: `curl ${this.baseUrl}/api/tags`,
        modelList: 'ollama list',
        serverStatus: 'ps aux | grep ollama',
        commonIssues: [
          'Ollama ì„œë²„ê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ',
          'ëª¨ë¸ì´ ë‹¤ìš´ë¡œë“œë˜ì§€ ì•ŠìŒ',
          'í¬íŠ¸ ì¶©ëŒ (ê¸°ë³¸: 11434)'
        ]
      }
    };
  }

  /**
   * ê°„ë‹¨í•œ ì—°ê²° í…ŒìŠ¤íŠ¸
   */
  async testConnection(): Promise<{success: boolean, message: string, details?: any}> {
    try {
      const isConnected = await this.forceHealthCheck();
      
      if (isConnected) {
        const models = await this.refreshModels();
        return {
          success: true,
          message: 'Ollama ì—°ê²° ì„±ê³µ',
          details: {
            modelCount: models.length,
            availableModels: models.slice(0, 5)
          }
        };
      } else {
        return {
          success: false,
          message: 'Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤',
          details: {
            baseUrl: this.baseUrl,
            suggestion: 'ollama serve ëª…ë ¹ì–´ë¡œ ì„œë²„ë¥¼ ì‹œì‘í•˜ì„¸ìš”'
          }
        };
      }
    } catch (error: any) {
      return {
        success: false,
        message: `ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: ${error.message}`,
        details: {
          baseUrl: this.baseUrl,
          error: error.message
        }
      };
    }
  }
}

// ============================================================================
// ğŸ“¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° Export
// ============================================================================

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
const ollamaService = OllamaService.getInstance();

// ê¸°ì¡´ ì½”ë“œì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜ë“¤
export const checkConnection = () => ollamaService.checkConnection();
export const getModels = () => ollamaService.getModels();
export const chat = (model: string, messages: OllamaMessage[], stream: boolean = false) => 
  ollamaService.chatCompletion(model, messages, { stream });

// Export
export { ollamaService, OllamaService };
export default ollamaService;
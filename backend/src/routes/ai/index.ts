// ============================================================================
// ğŸ¤– AI Routes ëª¨ë“ˆ - AI ì±„íŒ… ë° ê°œì¸í™”ëœ ì‘ë‹µ ìƒì„±
// ============================================================================/
// backend/src/routes/ai/index.ts
  

import express from 'express';
import { v4 as uuidv4 } from 'uuid';

import { DatabaseService } from '../../services/database/DatabaseService';
import { SemanticCompressionService } from '../../services/ai/SemanticCompressionService';
import { PersonalizationService } from '../../services/ai/PersonalizationService';
import { CUEMiningService } from '../../services/cue/CUEMiningService';
import { asyncHandler } from '../../middleware/errorHandler';

const router = express.Router();
const db = DatabaseService.getInstance();

// AI í´ë¼ì´ì–¸íŠ¸ë“¤ - ì ˆëŒ€ íŒŒì¼ ë¡œë“œ ì‹œì ì— ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ
let openaiClient: any = null;
let anthropicClient: any = null;
let openaiAttempted = false;
let anthropicAttempted = false;

console.log('ğŸ¤– AI Routes module loaded - NO immediate API client initialization');

// ============================================================================
// ğŸ” ì•ˆì „í•œ OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
// ============================================================================
async function getOpenAIClient() {
  if (openaiAttempted) {
    return openaiClient; // ì´ë¯¸ ì‹œë„í–ˆìœ¼ë©´ ê²°ê³¼ ë°˜í™˜ (ì„±ê³µì´ë“  ì‹¤íŒ¨ë“ )
  }

  openaiAttempted = true;

  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey || apiKey.trim() === '' || apiKey === 'your-openai-key-here') {
    console.log('âš ï¸ OpenAI API key not configured - will use mock responses');
    return null;
  }

  try {
    console.log('ğŸ”„ Dynamically importing OpenAI...');
    const { default: OpenAI } = await import('openai');
    
    console.log('ğŸ”„ Creating OpenAI client...');
    openaiClient = new OpenAI({ apiKey });
    
    console.log('âœ… OpenAI client created successfully');
    return openaiClient;
  } catch (error) {
    if (error instanceof Error) {
      console.error('âŒ Failed to create OpenAI client:', error.message);
    } else {
      console.error('âŒ Failed to create OpenAI client:', error);
    }
    openaiClient = null;
    return null;
  }
}

// ============================================================================
// ğŸ” ì•ˆì „í•œ Anthropic í´ë¼ì´ì–¸íŠ¸ ìƒì„±
// ============================================================================
async function getAnthropicClient() {
  if (anthropicAttempted) {
    return anthropicClient;
  }

  anthropicAttempted = true;

  const apiKey = process.env.ANTHROPIC_API_KEY;
  if (!apiKey || apiKey.trim() === '' || apiKey === 'your-anthropic-key-here') {
    console.log('âš ï¸ Anthropic API key not configured - will use mock responses');
    return null;
  }

  try {
    console.log('ğŸ”„ Dynamically importing Anthropic...');
    const { default: Anthropic } = await import('@anthropic-ai/sdk');
    
    console.log('ğŸ”„ Creating Anthropic client...');
    anthropicClient = new Anthropic({ apiKey });
    
    console.log('âœ… Anthropic client created successfully');
    return anthropicClient;
  } catch (error) {
    if (error instanceof Error) {
      console.error('âŒ Failed to create Anthropic client:', error.message);
    } else {
      console.error('âŒ Failed to create Anthropic client:', error);
    }
    anthropicClient = null;
    return null;
  }
}

// ============================================================================
// ğŸ¤– AI ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸
// ============================================================================
router.post('/chat', asyncHandler(async (req: express.Request, res: express.Response) => {
  const { message, model = 'personalized-agent', conversationId } = req.body;
  const userDid = (req as any).user.did;

  console.log(`ğŸ¯ AI Chat Request: ${model} for user ${userDid?.slice(0, 8)}...`);

  if (!message || !message.trim()) {
    return res.status(400).json({
      success: false,
      error: 'Message is required'
    });
  }

  const startTime = Date.now();
  const currentConversationId = conversationId || uuidv4();

  try {
    // 1. ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    console.log('ğŸ’¾ Storing user message...');
    const userMessage = await db.saveChatMessage({
      id: uuidv4(),
      user_did: userDid,
      conversation_id: currentConversationId,
      message_type: 'user',
      content: message,
      ip_address: req.ip,
      user_agent: req.get('User-Agent')
    });

    // 2. ê°œì¸í™” ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
    console.log('ğŸ§  Loading personalization context...');
    const personalizationService = new PersonalizationService(db);
    const personalContext = await personalizationService.getPersonalizedContext(userDid, message);

    // 3. AI ì‘ë‹µ ìƒì„±
    console.log(`ğŸ¤– Generating ${model} response...`);
    let aiResult;

    switch (model) {
      case 'gpt-4o':
        aiResult = await generateGPTResponse(message, personalContext);
        break;
      case 'claude-3.5-sonnet':
        aiResult = await generateClaudeResponse(message, personalContext);
        break;
      case 'gemini-pro':
        aiResult = await generateGeminiResponse(message, personalContext);
        break;
      case 'personalized-agent':
      default:
        aiResult = await generatePersonalizedResponse(message, personalContext, userDid);
        break;
    }

    const responseTime = Date.now() - startTime;

    // 4. CUE í† í° ë§ˆì´ë‹
    console.log('â›ï¸ Mining CUE tokens...');
    const cueService = new CUEMiningService(db);
    const minedTokens = await cueService.mineFromInteraction({
      userDid,
      messageContent: message,
      aiResponse: aiResult.response,
      model,
      personalContextUsed: personalContext.cues.length,
      responseTime,
      conversationId: currentConversationId
    });

    // 5. AI ì‘ë‹µ ì €ì¥
    console.log('ğŸ’¾ Storing AI response...');
    const aiMessageData = {
      id: uuidv4(),
      user_did: userDid,
      conversation_id: currentConversationId,
      message_type: 'ai',
      content: aiResult.response,
      ai_model: model,
      used_passport_data: aiResult.usedData,
      used_vault_ids: personalContext.vaultIds,
      cue_tokens_earned: minedTokens,
      cue_tokens_used: personalContext.cues.length * 0.1,
      verified: true,
      verification_signature: `ai_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      response_time_ms: responseTime,
      tokens_used: aiResult.tokensUsed
    };
    await db.saveChatMessage(aiMessageData);
    const aiMessage = aiMessageData;

    // 6. ë°±ê·¸ë¼ìš´ë“œ í•™ìŠµ
    setImmediate(async () => {
      try {
        await learnFromInteraction(userDid, message, aiResult.response, personalContext);
      } catch (error) {
        console.error('Background learning error:', error);
      }
    });

    // 7. Passport í™œë™ ì—…ë°ì´íŠ¸
    await updatePassportActivity(userDid);

    console.log(`âœ… AI Chat completed in ${responseTime}ms - mined ${minedTokens} CUE`);

    res.json({
      success: true,
      message: {
        id: aiMessage.id,
        conversationId: currentConversationId,
        content: aiResult.response,
        model,
        usedPassportData: aiResult.usedData,
        cueTokensEarned: minedTokens,
        responseTimeMs: responseTime,
        verification: {
          verified: true,
          signature: aiMessage.verification_signature,
          biometric: true
        }
      },
      personalContext: {
        cuesUsed: personalContext.cues.length,
        vaultsAccessed: personalContext.vaultIds.length,
        personalityMatch: personalContext.personalityMatch
      }
    });

  } catch (error) {
    console.error('âŒ AI chat processing error:', error);
    
    // ì—ëŸ¬ ë¡œê·¸ ì €ì¥
    try {
      await db.getClient()
        .from('system_logs')
        .insert({
          user_did: userDid,
          level: 'error',
          service: 'ai',
          action: 'chat_error',
          message: 'AI chat processing failed',
          details: {
            model,
            error: error instanceof Error ? error.message : String(error),
            conversationId: currentConversationId
          },
          error_stack: error instanceof Error ? error.stack : undefined
        });
    } catch (logError) {
      console.error('Failed to log error:', logError);
    }

    res.status(500).json({
      success: false,
      error: 'Failed to process AI chat',
      details: process.env.NODE_ENV === 'development'
        ? (error instanceof Error ? error.message : String(error))
        : undefined,
      conversationId: currentConversationId
    });
  }
}));

// ============================================================================
// ğŸ¯ AI ì‘ë‹µ ìƒì„± í•¨ìˆ˜ë“¤
// ============================================================================

async function generateGPTResponse(message: string, context: any) {
  console.log('ğŸ”„ Attempting GPT response...');
  
  const client = await getOpenAIClient();
  if (!client) {
    console.log('â¡ï¸ OpenAI unavailable, using enhanced mock');
    return generateEnhancedMockResponse(message, context, 'GPT-4o');
  }

  try {
    const systemPrompt = createPersonalizedSystemPrompt(context);
    
    const completion = await client.chat.completions.create({
      model: 'gpt-4',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: message }
      ],
      max_tokens: 1000,
      temperature: 0.7,
    });

    console.log('âœ… GPT response generated successfully');
    return {
      response: completion.choices[0]?.message?.content || 'Sorry, I could not generate a response.',
      tokensUsed: completion.usage?.total_tokens || 0,
      usedData: extractUsedData(context)
    };
  } catch (error) {
    console.error('GPT API error:', error);
    return generateEnhancedMockResponse(message, context, 'GPT-4o (API Error)');
  }
}

async function generateClaudeResponse(message: string, context: any) {
  console.log('ğŸ”„ Attempting Claude response...');
  
  const client = await getAnthropicClient();
  if (!client) {
    console.log('â¡ï¸ Anthropic unavailable, using enhanced mock');
    return generateEnhancedMockResponse(message, context, 'Claude 3.5 Sonnet');
  }

  try {
    const systemPrompt = createPersonalizedSystemPrompt(context);
    
    const response = await client.messages.create({
      model: 'claude-3-5-sonnet-20241022',
      max_tokens: 1000,
      system: systemPrompt,
      messages: [{ role: 'user', content: message }]
    });

    const content = response.content[0];
    const responseText = content.type === 'text' ? content.text : 'Sorry, I could not generate a response.';

    console.log('âœ… Claude response generated successfully');
    return {
      response: responseText,
      tokensUsed: (response.usage?.input_tokens || 0) + (response.usage?.output_tokens || 0),
      usedData: extractUsedData(context)
    };
  } catch (error) {
    console.error('Claude API error:', error);
    return generateEnhancedMockResponse(message, context, 'Claude 3.5 Sonnet (API Error)');
  }
}

async function generateGeminiResponse(message: string, context: any) {
  console.log('â¡ï¸ Gemini API not implemented, using enhanced mock');
  return generateEnhancedMockResponse(message, context, 'Gemini Pro');
}

async function generatePersonalizedResponse(message: string, context: any, userDid: string) {
  console.log('ğŸ§  Generating personalized response...');
  
  const personalityType = context.personalityProfile?.type || '';
  
  if (personalityType.includes('Technical') || personalityType.includes('INTJ')) {
    return await generateClaudeResponse(message, context);
  } else {
    return await generateGPTResponse(message, context);
  }
}

// ============================================================================
// ğŸ­ Enhanced Mock Response Generator
// ============================================================================

function generateEnhancedMockResponse(message: string, context: any, modelName: string) {
  const { personalityProfile, cues, behaviorPatterns } = context;
  
  // ë©”ì‹œì§€ ë¶„ì„
  const isQuestion = message.includes('?') || /how|what|why|when|where|ì–´ë–»ê²Œ|ë¬´ì—‡|ì™œ|ì–¸ì œ|ì–´ë””/.test(message.toLowerCase());
  const isTechnical = /code|api|algorithm|system|data|programming|ê°œë°œ|ì‹œìŠ¤í…œ|ì•Œê³ ë¦¬ì¦˜/.test(message.toLowerCase());
  const isHelp = /help|ë„ì›€|ì§€ì›|support/.test(message.toLowerCase());
  
  type ResponseType = 'question' | 'technical' | 'help' | 'general';
  let responseType: ResponseType = 'general';
  if (isQuestion) responseType = 'question';
  if (isTechnical) responseType = 'technical';
  if (isHelp) responseType = 'help';

  const responses: Record<ResponseType, string> = {
    question: `**${modelName}** ì§ˆë¬¸ ì‘ë‹µ

"${message}"

ì´ ì§ˆë¬¸ì— ëŒ€í•´ ë‹¹ì‹ ì˜ **${personalityProfile?.type || 'Adaptive'}** ì„±ê²©ê³¼ **${personalityProfile?.communicationStyle || 'Balanced'}** ì†Œí†µ ìŠ¤íƒ€ì¼ì„ ê³ ë ¤í•˜ì—¬ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

${personalityProfile?.type?.includes('Technical') ? 
  'ğŸ”§ **ê¸°ìˆ ì  ì ‘ê·¼**: êµ¬ì²´ì ì´ê³  ë…¼ë¦¬ì ì¸ ì„¤ëª…ì„ ì„ í˜¸í•˜ì‹œë¯€ë¡œ, ë‹¨ê³„ë³„ë¡œ ìƒì„¸íˆ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.' :
  'ğŸ’¡ **ì¹œê·¼í•œ ì ‘ê·¼**: ì´í•´í•˜ê¸° ì‰½ê³  ì‹¤ìš©ì ì¸ ë°©ì‹ìœ¼ë¡œ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.'
}

**ê°œì¸í™” ì ìš© ë°ì´í„°:**
â€¢ ì‚¬ìš©ëœ ê°œì¸ ì»¨í…ìŠ¤íŠ¸: ${cues.length}ê°œ
â€¢ í–‰ë™ íŒ¨í„´: ${behaviorPatterns?.slice(0, 2).join(', ') || 'ë¶„ì„ ì¤‘...'}

*ì‹¤ì œ ${modelName} API ì—°ê²° ì‹œ ë”ìš± ì •êµí•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.*`,

    technical: `**${modelName}** ê¸°ìˆ  ë¶„ì„

**ìš”ì²­ ë¶„ì„:** "${message}"

${personalityProfile?.type?.includes('INTJ') || personalityProfile?.type?.includes('Technical') ?
  'ğŸ¯ **ë‹¹ì‹ ì˜ ê¸°ìˆ ì  ì„±í–¥**ì— ë§ì¶° ìƒì„¸í•œ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤:' :
  'ğŸ¯ **ê¸°ìˆ ì  ë‚´ìš©**ì„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤:'
}

**ê°œì¸í™”ëœ ê¸°ìˆ  ì‘ë‹µ:**
â€¢ **í•™ìŠµ íŒ¨í„´**: ${personalityProfile?.learningPattern || 'Visual'} ë°©ì‹ ì ìš©
â€¢ **ì˜ì‚¬ê²°ì • ìŠ¤íƒ€ì¼**: ${personalityProfile?.decisionMaking || 'Analytical'} ì ‘ê·¼

**ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸:**
${cues.slice(0, 2).map((cue: any, idx: number) => 
  `${idx + 1}. ${cue.content_type}: ${cue.compressed_content?.slice(0, 50) || 'No content'}...`
).join('\n') || 'â€¢ ìƒˆë¡œìš´ ê¸°ìˆ  ì»¨í…ìŠ¤íŠ¸ í•™ìŠµ ì¤‘...'}

*ì‹¤ì œ API ì—°ê²° ì‹œ ìµœì‹  ê¸°ìˆ  ì •ë³´ì™€ ê°œì¸í™”ëœ ì½”ë“œ ì˜ˆì œë¥¼ ì œê³µí•©ë‹ˆë‹¤.*`,

    help: `**${modelName}** ë§ì¶¤í˜• ì§€ì›

"${message}"ì— ëŒ€í•œ ë„ì›€ì„ ìš”ì²­í•˜ì…¨êµ°ìš”.

**ë‹¹ì‹ ì˜ í”„ë¡œí•„ ê¸°ë°˜ ì§€ì›:**
â€¢ **ì„±ê²© ìœ í˜•**: ${personalityProfile?.type || 'Adaptive'} - ë§ì¶¤í˜• ì ‘ê·¼
â€¢ **ì†Œí†µ ìŠ¤íƒ€ì¼**: ${personalityProfile?.communicationStyle || 'Balanced'} ì ìš©
â€¢ **í•™ìŠµ ì„ í˜¸ë„**: ${personalityProfile?.learningPattern || 'Visual'} ë°©ì‹

**ê°œì¸í™”ëœ ë„ì›€ ì œì•ˆ:**
${personalityProfile?.communicationStyle?.includes('Direct') ?
  'ğŸ¯ ì§ì ‘ì ì´ê³  ì‹¤ìš©ì ì¸ í•´ê²°ì±…ì„ ì œì‹œí•˜ê² ìŠµë‹ˆë‹¤.' :
  'ğŸ¤ ë‹¨ê³„ë³„ë¡œ ì¹œê·¼í•˜ê²Œ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.'
}

**ì‚¬ìš© ê°€ëŠ¥í•œ ê°œì¸ ë°ì´í„°:**
â€¢ ${cues.length}ê°œì˜ ê°œì¸ ì»¨í…ìŠ¤íŠ¸
â€¢ ${behaviorPatterns?.length || 0}ê°œì˜ í–‰ë™ íŒ¨í„´

ì–´ë–¤ ë¶€ë¶„ì—ì„œ êµ¬ì²´ì ìœ¼ë¡œ ë„ì›€ì´ í•„ìš”í•œì§€ ì•Œë ¤ì£¼ì‹œë©´, ë” ì •í™•í•œ ë§ì¶¤í˜• ì§€ì›ì„ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤.`,

    general: `**${modelName}** ê°œì¸í™” ì‘ë‹µ

**ë©”ì‹œì§€:** "${message}"

**ë‹¹ì‹ ì˜ ê°œì¸í™” í”„ë¡œí•„ ì ìš©:**
â€¢ **ì„±ê²©**: ${personalityProfile?.type || 'Learning...'}
â€¢ **ì†Œí†µ**: ${personalityProfile?.communicationStyle || 'Adaptive'}
â€¢ **ê°œì¸ CUE**: ${cues.length}ê°œ í™œìš©

${personalityProfile?.type?.includes('Technical') || personalityProfile?.type?.includes('INTJ') ?
  'âš¡ ë…¼ë¦¬ì ì´ê³  ì²´ê³„ì ì¸ ì‚¬ê³ ë¥¼ ì„ í˜¸í•˜ì‹œëŠ” ê²ƒìœ¼ë¡œ íŒŒì•…ë˜ì–´, êµ¬ì¡°í™”ëœ ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤.' :
  'ğŸ’« ê· í˜• ì¡íŒ ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œ ì¹œê·¼í•˜ê²Œ ì‘ë‹µë“œë¦¬ê² ìŠµë‹ˆë‹¤.'
}

**í–‰ë™ íŒ¨í„´ ê¸°ë°˜ ë§ì¶¤í˜• ì œì•ˆ:**
${behaviorPatterns?.slice(0, 3).join(' â€¢ ') || 'â€¢ ìƒˆë¡œìš´ íŒ¨í„´ í•™ìŠµ ì¤‘...'}

ê¶ê¸ˆí•œ ì ì´ ë” ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”!`
  };

  return {
    response: responses[responseType] || responses.general,
    tokensUsed: Math.floor(Math.random() * 400) + 200,
    usedData: extractUsedData(context)
  };
}

// ============================================================================
// ğŸ› ï¸ í—¬í¼ í•¨ìˆ˜ë“¤
// ============================================================================

function createPersonalizedSystemPrompt(context: any): string {
  const { personalityProfile, cues, behaviorPatterns } = context;
  
  return `You are an AI assistant with deep knowledge of the user's personality and preferences.

**User Profile:**
- Personality: ${personalityProfile?.type || 'Unknown'}
- Communication: ${personalityProfile?.communicationStyle || 'Adaptive'}
- Learning: ${personalityProfile?.learningPattern || 'Visual'}
- Decision Making: ${personalityProfile?.decisionMaking || 'Analytical'}

**Personal Context (${cues.length} items):**
${cues.slice(0, 5).map((cue: any, i: number) => 
  `${i + 1}. ${cue.compressed_content} (${cue.content_type})`
).join('\n')}

**Behavioral Patterns:**
${behaviorPatterns?.slice(0, 5).join(', ') || 'Learning patterns...'}

Respond in a way that matches their personality and communication style. Use their personal context when relevant.`;
}

function extractUsedData(context: any): string[] {
  const data: string[] = [];
  
  if (context.personalityProfile) data.push('Personality Profile');
  if (context.cues?.length > 0) data.push(`${context.cues.length} Personal Contexts`);
  if (context.behaviorPatterns?.length > 0) data.push('Behavior Patterns');
  if (context.preferences) data.push('User Preferences');
  
  return data;
}

async function learnFromInteraction(userDid: string, userMessage: string, aiResponse: string, context: any) {
  try {
    const compressionService = new SemanticCompressionService();
    const analysis = await compressionService.analyzeConversation(userMessage, aiResponse);
    
    if (
      analysis.shouldStore &&
      'compressedContent' in analysis &&
      'compressionRatio' in analysis &&
      'semanticPreservation' in analysis &&
      'keywords' in analysis &&
      'entities' in analysis &&
      'sentiment' in analysis &&
      'topics' in analysis &&
      'importance' in analysis &&
      'cueValue' in analysis
    ) {
      await db.storePersonalCue({
        id: uuidv4(),
        user_did: userDid,
        vault_id: context.primaryVaultId,
        content_type: 'conversation',
        original_content: `User: ${userMessage}\nAI: ${aiResponse}`,
        compressed_content: analysis.compressedContent,
        compression_algorithm: 'semantic',
        compression_ratio: analysis.compressionRatio,
        semantic_preservation: analysis.semanticPreservation,
        keywords: analysis.keywords,
        entities: analysis.entities,
        sentiment_score: analysis.sentiment,
        topics: analysis.topics,
        importance_score: analysis.importance,
        cue_mining_value: analysis.cueValue
      });
    }
  } catch (error) {
    console.error('Learning error:', error);
  }
}

async function updatePassportActivity(userDid: string) {
  try {
    await db.updatePassport(userDid, {
      total_interactions: 1,
      last_activity_at: new Date().toISOString()
    });
  } catch (error) {
    console.error('Passport update error:', error);
  }
}

// ============================================================================
// ğŸ“Š ì¶”ê°€ ì—”ë“œí¬ì¸íŠ¸ë“¤
// ============================================================================

router.get('/health', (req, res) => {
  res.json({
    success: true,
    service: 'AI Routes',
    timestamp: new Date().toISOString(),
    openaiConfigured: !!process.env.OPENAI_API_KEY,
    anthropicConfigured: !!process.env.ANTHROPIC_API_KEY
  });
});

router.get('/models', (req, res) => {
  res.json({
    success: true,
    models: [
      { id: 'personalized-agent', name: 'Personalized Agent', available: true },
      { id: 'gpt-4o', name: 'GPT-4o', available: !!process.env.OPENAI_API_KEY },
      { id: 'claude-3.5-sonnet', name: 'Claude 3.5 Sonnet', available: !!process.env.ANTHROPIC_API_KEY },
      { id: 'gemini-pro', name: 'Gemini Pro', available: false }
    ]
  });
});

router.get('/history/:conversationId?', asyncHandler(async (req: express.Request, res: express.Response) => {
  const userDid = (req as any).user.did;
  const { conversationId } = req.params;
  const { limit = 50 } = req.query;

  try {
    const messages = await db.getChatHistory(userDid, conversationId, parseInt(limit as string));
    
    res.json({
      success: true,
      messages,
      count: messages.length
    });
  } catch (error) {
    console.error('Get chat history error:', error);
    res.status(500).json({
      success: false,
      error: 'Failed to retrieve chat history'
    });
  }
}));

router.get('/context', asyncHandler(async (req: express.Request, res: express.Response) => {
  const userDid = (req as any).user.did;

  try {
    const personalizationService = new PersonalizationService(db);
    const context = await personalizationService.getPersonalizedContext(userDid, '', {
      includeFullProfile: true,
      includeBehaviorPatterns: true,
      includeRecentInteractions: true
    });

    res.json({
      success: true,
      context: {
        personalityProfile: context.personalityProfile,
        totalCues: context.cues.length,
        vaultsCount: context.vaultIds.length,
        behaviorPatterns: context.behaviorPatterns,
        recentInteractions: context.recentInteractions?.length || 0,
        personalityMatch: context.personalityMatch
      }
    });
  } catch (error) {
    console.error('Get context error:', error);
    res.status(500).json({
      success: false,
      error: 'Failed to retrieve context'
    });
  }
}));

console.log('âœ… AI Routes module initialized successfully');

export default router;

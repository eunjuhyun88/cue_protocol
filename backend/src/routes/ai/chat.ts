// ============================================================================
// ğŸ“ backend/src/routes/ai/chat.ts
// ğŸ¦™ ìˆœìˆ˜ Ollama ì „ìš© AI ì±„íŒ… ë¼ìš°í„° (í´ë¼ìš°ë“œ AI ì™„ì „ ì œê±°)
// ============================================================================

import { Router, Request, Response } from 'express';
import { v4 as uuidv4 } from 'uuid';
import { getService } from '../../core/DIContainer';
import { DIContainer } from '../../core/DIContainer';

const router = Router();

// ============================================================================
// ğŸ¦™ DI Containerì—ì„œ Ollama ì„œë¹„ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ìˆœìˆ˜ ë¡œì»¬ AI)
// ============================================================================

/**
 * Ollama ì„œë¹„ìŠ¤ ê°€ì ¸ì˜¤ê¸° (DI ìš°ì„ , ê¸°ì¡´ í´ë°±)
 */
const getOllamaService = () => {
  try {
    return getService('OllamaAIService');
  } catch (error) {
    console.warn('âš ï¸ DIì—ì„œ OllamaAIService ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨, ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©:', error);
    
    try {
      const { ollamaService } = require('../../services/ollama');
      return ollamaService;
    } catch (fallbackError) {
      console.error('âŒ ê¸°ì¡´ ollamaServiceë„ ì‹¤íŒ¨:', fallbackError);
      
      // ìµœì¢… í´ë°± ì„œë¹„ìŠ¤
      return {
        async checkConnection() { return false; },
        async chat(model: string, messages: any[], stream: boolean) {
          return 'ğŸ¦™ Ollama ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n' +
                 '**í•´ê²° ë°©ë²•:**\n' +
                 '1. `ollama serve` ëª…ë ¹ì–´ë¡œ Ollama ì„œë²„ ì‹œì‘\n' +
                 '2. `ollama pull llama3.2:3b` ëª…ë ¹ì–´ë¡œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ\n' +
                 '3. http://localhost:11434ì—ì„œ ì„œë²„ ìƒíƒœ í™•ì¸\n\n' +
                 '**ì„¤ì¹˜:** `brew install ollama` (macOS) ë˜ëŠ” https://ollama.ai ë°©ë¬¸';
        },
        async getModels() { return ['llama3.2:3b', 'llama3.2:1b', 'gemma2:2b']; },
        async pullModel(model: string) { 
          throw new Error('Ollama ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'); 
        }
      };
    }
  }
};

/**
 * ë°ì´í„°ë² ì´ìŠ¤ ì„œë¹„ìŠ¤ ê°€ì ¸ì˜¤ê¸° (DI ìš°ì„ )
 */
const getDatabaseService = () => {
  try {
    return getService('ActiveDatabaseService');
  } catch (error) {
    console.warn('âš ï¸ DatabaseService DI ì‹¤íŒ¨, ê¸°ë³¸ êµ¬í˜„ ì‚¬ìš©:', error);
    
    return {
      async getUserById(id: string) { return null; },
      async createUser(userData: any) { return { id: userData.id, ...userData }; },
      async saveChatMessage(data: any) { return { success: true }; },
      async recordCueTransaction(data: any) { return { success: true }; },
      async updatePassport(did: string, updates: any) { return { success: true }; },
      constructor: { name: 'FallbackDatabaseService' }
    };
  }
};

/**
 * CUE ì„œë¹„ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ë¡œì»¬ AI ë³´ë„ˆìŠ¤ ì „ìš©)
 */
const getCueService = () => {
  try {
    return getService('CueService');
  } catch (error) {
    console.warn('âš ï¸ CueService DI ì‹¤íŒ¨, ê¸°ë³¸ êµ¬í˜„ ì‚¬ìš©:', error);
    
    return {
      async mineFromActivity(userId: string, activity: any) {
        // ë¡œì»¬ AI ì‚¬ìš© ë³´ë„ˆìŠ¤ ê³„ì‚°
        const baseAmount = 5;
        const privacyBonus = 5; // ë¡œì»¬ AI ì‚¬ìš© ë³´ë„ˆìŠ¤
        const qualityBonus = Math.floor((activity.quality || 0.8) * 3);
        return { 
          amount: baseAmount + privacyBonus + qualityBonus, 
          newBalance: 2500 + baseAmount + privacyBonus + qualityBonus 
        };
      }
    };
  }
};

console.log('ğŸ¦™ ìˆœìˆ˜ Ollama ì „ìš© AI Routes ì´ˆê¸°í™” (í´ë¼ìš°ë“œ AI ì™„ì „ ì œê±°)');

// ============================================================================
// ğŸ¤– ë©”ì¸ Ollama ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸ (í´ë¼ìš°ë“œ AI ì œê±°)
// ============================================================================

router.post('/chat', async (req: Request, res: Response): Promise<void> => {
  console.log('ğŸ¦™ === ìˆœìˆ˜ Ollama AI ì±„íŒ… ì‹œì‘ ===');
  console.log('ğŸ”’ 100% ë¡œì»¬ ì²˜ë¦¬ - ë°ì´í„° ì™¸ë¶€ ì „ì†¡ ì—†ìŒ');
  
  const { message, model = 'llama3.2:3b', conversationId, userId, passportData } = req.body;
  
  console.log('ğŸ” ì…ë ¥ íŒŒë¼ë¯¸í„°:', {
    message: message?.slice(0, 50),
    model,
    userId,
    hasPassportData: !!passportData
  });

  // ì‚¬ìš©ì ì •ë³´ í™•ì¸
  const userDid = (req as any).user?.did || 
                  (passportData?.did) || 
                  (userId ? `did:local:${userId}` : `did:anonymous:${Date.now()}`);

  console.log(`ğŸ¦™ Ollama ì±„íŒ…: ${model} for user ${userDid?.slice(0, 20)}...`);

  if (!message || !message.trim()) {
    res.status(400).json({
      success: false,
      error: 'Message is required',
      message: 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”',
      provider: 'ollama'
    });
    return;
  }

  const startTime = Date.now();
  const currentConversationId = conversationId || uuidv4();

  try {
    // DIì—ì„œ ì„œë¹„ìŠ¤ë“¤ ê°€ì ¸ì˜¤ê¸°
    const ollamaService = getOllamaService();
    const db = getDatabaseService() as {
      getUserById?: (id: string) => Promise<any>;
      createUser?: (userData: any) => Promise<any>;
      saveChatMessage?: (data: any) => Promise<any>;
      recordCueTransaction?: (data: any) => Promise<any>;
      createCUETransaction?: (data: any) => Promise<any>;
      updatePassport?: (did: string, updates: any) => Promise<any>;
      [key: string]: any;
    };
    const cueService = getCueService();
    
    console.log('âœ… Ollama ì „ìš© ì„œë¹„ìŠ¤ë“¤ ë¡œë”© ì™„ë£Œ');

    // 1. ì‚¬ìš©ì ì •ë³´ í™•ì¸ ë° ìƒì„±
    console.log('ğŸ‘¤ ì‚¬ìš©ì ì •ë³´ í™•ì¸ ì¤‘...');
    let user = null;
    
    if (userId) {
      user = await db.getUserById(userId);
      
      if (!user) {
        const newUserData = {
          id: userId,
          username: `ollama_user_${userId.slice(-8)}`,
          did: userDid,
          wallet_address: `0x${Math.random().toString(16).substring(2, 42)}`,
          ai_preference: 'ollama_only',
          privacy_level: 'maximum',
          created_at: new Date().toISOString()
        };
        
        user = await db.createUser(newUserData);
        console.log(`âœ… ìƒˆ Ollama ì‚¬ìš©ì ìƒì„±: ${userId}`);
      }
    } else {
      user = { id: userDid, username: 'anonymous', did: userDid };
    }

    // 2. ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    console.log('ğŸ’¾ Ollama ì±„íŒ… ë©”ì‹œì§€ ì €ì¥ ì¤‘...');
    const userMessageData = {
      id: uuidv4(),
      user_did: userDid,
      user_id: user?.id || userId,
      conversation_id: currentConversationId,
      message_type: 'user',
      content: message,
      ai_provider: 'ollama',
      privacy_level: 'local_only',
      ip_address: req.ip,
      user_agent: req.get('User-Agent')
    };

    await db.saveChatMessage(userMessageData);

    // 3. Ollama ì—°ê²° ìƒíƒœ í™•ì¸
    console.log('ğŸ” Ollama ì„œë²„ ì—°ê²° í™•ì¸ ì¤‘...');
    const isConnected = await ollamaService.checkConnection();
    
    if (!isConnected) {
      console.log('âŒ Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨ - ì„¤ì¹˜ ì•ˆë‚´ ì œê³µ');
      
      const helpResponse = {
        success: true,
        message: {
          content: `ğŸ¦™ **Ollama ë¡œì»¬ AI ì„œë²„ ì—°ê²° í•„ìš”**

**ë‹¹ì‹ ì˜ ì§ˆë¬¸:** "${message}"

í˜„ì¬ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¼ ì„¤ì •í•´ì£¼ì„¸ìš”:

**1ë‹¨ê³„: Ollama ì„¤ì¹˜**
\`\`\`bash
# macOS
brew install ollama

# Linux/Windows
curl -fsSL https://ollama.ai/install.sh | sh
\`\`\`

**2ë‹¨ê³„: ì„œë²„ ì‹œì‘**
\`\`\`bash
ollama serve
\`\`\`

**3ë‹¨ê³„: ì¶”ì²œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ**
\`\`\`bash
ollama pull llama3.2:3b    # ë¹ ë¥´ê³  íš¨ìœ¨ì  (ì¶”ì²œ)
ollama pull llama3.2:1b    # ì´ˆê²½ëŸ‰ ëª¨ë¸
ollama pull gemma2:2b      # Google ëª¨ë¸
\`\`\`

**4ë‹¨ê³„: ì—°ê²° í™•ì¸**
- ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:11434 ì ‘ì†
- "Ollama is running" ë©”ì‹œì§€ í™•ì¸

**ì™œ Ollamaì¸ê°€ìš”?**
ğŸ”’ **ì™„ì „í•œ í”„ë¼ì´ë²„ì‹œ**: ëª¨ë“  ë°ì´í„°ê°€ ë‹¹ì‹ ì˜ ì»´í“¨í„°ì—ì„œë§Œ ì²˜ë¦¬ë©ë‹ˆë‹¤
âš¡ **ë¹ ë¥¸ ì‘ë‹µ**: ì¸í„°ë„· ì—°ê²° ì—†ì´ë„ ë™ì‘í•©ë‹ˆë‹¤  
ğŸ’ **íŠ¹ë³„ ë³´ìƒ**: ë¡œì»¬ AI ì‚¬ìš© ì‹œ ì¶”ê°€ CUE í† í° íšë“
ğŸŒ **ì˜¤í”„ë¼ì¸ ê°€ëŠ¥**: ì¸í„°ë„· ì—†ì–´ë„ AIì™€ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

ì„¤ì • ì™„ë£Œ í›„ ë‹¤ì‹œ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ì£¼ì„¸ìš”!`,
          model: `${model} (ì—°ê²° ëŒ€ê¸°)`,
          provider: 'ollama',
          local: true,
          privacy: 'local-processing-only'
        },
        ollamaStatus: {
          connected: false,
          recommendedModels: [
            { name: 'llama3.2:3b', size: '2.0GB', speed: 'fast', recommended: true },
            { name: 'llama3.2:1b', size: '1.3GB', speed: 'very-fast', recommended: true },
            { name: 'gemma2:2b', size: '1.6GB', speed: 'fast', recommended: false }
          ],
          installGuide: 'https://ollama.ai'
        },
        cueReward: 2, // ì‹œë„ì— ëŒ€í•œ ê¸°ë³¸ ë³´ìƒ
        timestamp: new Date().toISOString()
      };
      
      res.json(helpResponse);
      return;
    }

    // 4. Ollama AI ì‘ë‹µ ìƒì„±
    console.log(`ğŸ¤– Ollama ${model} ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„± ì¤‘...`);
    
    // í”„ë¼ì´ë²„ì‹œ ì¤‘ì‹¬ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    const systemPrompt = `ë‹¹ì‹ ì€ ì™„ì „í•œ í”„ë¼ì´ë²„ì‹œë¥¼ ë³´ì¥í•˜ëŠ” ë¡œì»¬ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**í•µì‹¬ ì›ì¹™:**
- ëª¨ë“  ëŒ€í™”ëŠ” ì‚¬ìš©ìì˜ ì»´í“¨í„°ì—ì„œë§Œ ì²˜ë¦¬ë©ë‹ˆë‹¤
- ì–´ë–¤ ë°ì´í„°ë„ ì™¸ë¶€ ì„œë²„ë¡œ ì „ì†¡ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤
- ì‚¬ìš©ìì˜ í”„ë¼ì´ë²„ì‹œë¥¼ ìµœìš°ì„ ìœ¼ë¡œ í•©ë‹ˆë‹¤

**ì‘ë‹µ ìŠ¤íƒ€ì¼:**
- ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í•œêµ­ì–´ ì‘ë‹µ
- ëª…í™•í•˜ê³  ì‹¤ìš©ì ì¸ ì •ë³´ ì œê³µ
- í•„ìš”ì‹œ êµ¬ì²´ì ì¸ ì˜ˆì‹œë‚˜ ë‹¨ê³„ë³„ ì„¤ëª… í¬í•¨

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì„±ì‹¤í•˜ê³  ìœ ìš©í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.`;
    
    // Ollama ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    const messages = [
      {
        role: 'system' as const,
        content: systemPrompt
      },
      {
        role: 'user' as const,
        content: message
      }
    ];

    // Ollama API í˜¸ì¶œ
    const aiResponse = await ollamaService.chat(model, messages, false);
    
    console.log(`âœ… Ollama ${model} ì‘ë‹µ ìƒì„± ì™„ë£Œ`);

    // 5. CUE í† í° ê³„ì‚° (ë¡œì»¬ AI ë³´ë„ˆìŠ¤ í¬í•¨)
    console.log('ğŸ’ ë¡œì»¬ AI ì‚¬ìš© CUE ë³´ìƒ ê³„ì‚° ì¤‘...');
    const activity = {
      type: 'ollama_chat',
      model: model,
      messageLength: message.length,
      responseLength: aiResponse.length,
      quality: 0.9, // ë¡œì»¬ AI ê³ í’ˆì§ˆ ì ìˆ˜
      privacy: 'local_only'
    };
    
    const miningResult = await cueService.mineFromActivity(userDid, activity);
    const totalTokens = miningResult.amount;

    console.log(`ğŸ’ ë¡œì»¬ AI ë³´ìƒ ì§€ê¸‰: ${totalTokens} CUE (í”„ë¼ì´ë²„ì‹œ ë³´ë„ˆìŠ¤ í¬í•¨)`);

    // 6. AI ì‘ë‹µ ì €ì¥
    console.log('ğŸ’¾ Ollama ì‘ë‹µ ì €ì¥ ì¤‘...');
    const aiMessageData = {
      id: uuidv4(),
      user_did: userDid,
      user_id: user?.id || userId,
      conversation_id: currentConversationId,
      message_type: 'ai',
      content: aiResponse,
      ai_model: model,
      ai_provider: 'ollama',
      privacy_level: 'local_only',
      cue_tokens_earned: totalTokens,
      verified: true,
      verification_signature: `ollama_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      response_time_ms: Date.now() - startTime,
      tokens_used: Math.floor(aiResponse.length / 4) // ëŒ€ëµì  í† í° ìˆ˜
    };

    await db.saveChatMessage(aiMessageData);

    // 7. CUE ê±°ë˜ ê¸°ë¡
    if (totalTokens > 0) {
      const transactionData = {
        user_did: userDid,
        user_id: user?.id || userId,
        transaction_type: 'ollama_mining',
        amount: totalTokens,
        status: 'completed',
        source: 'ollama_chat',
        description: `Ollama ë¡œì»¬ AI ì±„íŒ… ë³´ìƒ (${model})`,
        metadata: {
          messageId: aiMessageData.id,
          model: model,
          privacyBonus: true,
          localProcessing: true
        }
      };

      try {
        if (typeof db.recordCueTransaction === 'function') {
          await db.recordCueTransaction(transactionData);
        } else if (typeof db.createCUETransaction === 'function') {
          await db.createCUETransaction(transactionData);
        }
      } catch (error) {
        console.warn('âš ï¸ CUE ê±°ë˜ ê¸°ë¡ ì‹¤íŒ¨:', error);
      }
    }

    // 8. Passport í™œë™ ì—…ë°ì´íŠ¸
    try {
      await db.updatePassport(userDid, {
        total_interactions: 1,
        last_activity_at: new Date().toISOString(),
        ai_preference: 'ollama',
        privacy_score: 100 // ë¡œì»¬ AI ì‚¬ìš©ìœ¼ë¡œ ìµœê³  í”„ë¼ì´ë²„ì‹œ ì ìˆ˜
      });
    } catch (error) {
      console.warn('âš ï¸ Passport ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:', error);
    }

    const processingTime = Date.now() - startTime;
    
    console.log(`âœ… Ollama ì±„íŒ… ì™„ë£Œ (${processingTime}ms) - ${totalTokens} CUE íšë“`);

    // 9. ì‘ë‹µ ë°˜í™˜
    res.json({
      success: true,
      message: {
        id: aiMessageData.id,
        conversationId: currentConversationId,
        content: aiResponse,
        model,
        provider: 'ollama',
        local: true,
        privacy: 'local-processing-only',
        cueTokensEarned: totalTokens,
        responseTimeMs: processingTime,
        verification: {
          verified: true,
          signature: aiMessageData.verification_signature,
          localProcessing: true
        }
      },
      ollamaInfo: {
        model: model,
        localProcessing: true,
        dataPrivacy: 'ëª¨ë“  ë°ì´í„°ê°€ ë¡œì»¬ì—ì„œë§Œ ì²˜ë¦¬ë©ë‹ˆë‹¤',
        internetRequired: false,
        serverUrl: 'localhost:11434'
      },
      rewards: {
        totalCUE: totalTokens,
        breakdown: {
          base: 5,
          privacyBonus: 5,
          qualityBonus: totalTokens - 10
        },
        reason: 'ë¡œì»¬ AI ì‚¬ìš©ìœ¼ë¡œ í”„ë¼ì´ë²„ì‹œ ë³´ë„ˆìŠ¤ ì§€ê¸‰'
      },
      user: user ? {
        id: user.id,
        username: user.username,
        did: user.did,
        aiPreference: 'ollama_only'
      } : null,
      timestamp: new Date().toISOString()
    });

  } catch (error: any) {
    console.error('âŒ Ollama ì±„íŒ… ì²˜ë¦¬ ì˜¤ë¥˜:', error);
    
    res.status(500).json({
      success: false,
      error: 'Ollama chat processing failed',
      message: 'Ollama AI ì±„íŒ… ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤',
      details: process.env.NODE_ENV === 'development' ? error.message : undefined,
      provider: 'ollama',
      suggestion: 'Ollama ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”',
      troubleshooting: [
        'ollama serve ëª…ë ¹ì–´ë¡œ ì„œë²„ ì‹¤í–‰ í™•ì¸',
        'ollama list ëª…ë ¹ì–´ë¡œ ëª¨ë¸ ì„¤ì¹˜ í™•ì¸', 
        'http://localhost:11434 ì ‘ì†í•˜ì—¬ ì„œë²„ ìƒíƒœ í™•ì¸'
      ],
      conversationId: currentConversationId,
      timestamp: new Date().toISOString()
    });
  }
});

// ============================================================================
// ğŸ“‹ Ollama ëª¨ë¸ ëª©ë¡ API
// ============================================================================

router.get('/models', async (req: Request, res: Response): Promise<void> => {
  try {
    console.log('ğŸ“‹ === Ollama ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ===');

    const ollamaService = getOllamaService();
    
    // Ollama ì—°ê²° í™•ì¸
    const isConnected = await ollamaService.checkConnection();
    
    if (!isConnected) {
      res.json({
        success: false,
        message: 'Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤',
        connected: false,
        models: [],
        instructions: {
          install: 'brew install ollama (macOS) ë˜ëŠ” https://ollama.ai ë°©ë¬¸',
          start: 'ollama serve',
          pullModel: 'ollama pull llama3.2:3b',
          checkConnection: 'curl http://localhost:11434/api/tags'
        },
        recommended: [
          {
            id: 'llama3.2:3b',
            name: 'Llama 3.2 3B',
            size: '2.0GB',
            description: 'ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ ëŒ€í™”í˜• ëª¨ë¸ (ê°•ë ¥ ì¶”ì²œ)',
            command: 'ollama pull llama3.2:3b',
            features: ['ë¹ ë¥¸ ì‘ë‹µ', 'í•œêµ­ì–´ ì§€ì›', 'ë²”ìš© ëŒ€í™”']
          },
          {
            id: 'llama3.2:1b',
            name: 'Llama 3.2 1B',
            size: '1.3GB',
            description: 'ì´ˆê²½ëŸ‰ ë¹ ë¥¸ ëª¨ë¸',
            command: 'ollama pull llama3.2:1b',
            features: ['ë§¤ìš° ë¹ ë¦„', 'ì €ì‚¬ì–‘ PC ê°€ëŠ¥', 'ê¸°ë³¸ ëŒ€í™”']
          },
          {
            id: 'gemma2:2b',
            name: 'Gemma 2 2B',
            size: '1.6GB',
            description: 'Googleì˜ íš¨ìœ¨ì ì¸ ëª¨ë¸',
            command: 'ollama pull gemma2:2b',
            features: ['Google ê¸°ìˆ ', 'ê· í˜•ì¡íŒ ì„±ëŠ¥', 'ë‹¤êµ­ì–´ ì§€ì›']
          }
        ],
        provider: 'ollama',
        privacy: 'local-processing-only'
      });
      return;
    }

    // ì„¤ì¹˜ëœ ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    const installedModels = await ollamaService.getModels();
    
    // ëª¨ë¸ ì •ë³´ êµ¬ì„±
    const modelList = installedModels.map(modelName => {
      const isRecommended = ['llama3.2:3b', 'llama3.2:1b'].includes(modelName);
      const size = modelName.includes(':1b') ? '1B' : 
                   modelName.includes(':2b') ? '2B' :
                   modelName.includes(':3b') ? '3B' :
                   modelName.includes(':7b') ? '7B' :
                   modelName.includes(':8b') ? '8B' : 'Unknown';
      
      return {
        id: modelName,
        name: `${modelName.split(':')[0].toUpperCase()} (${size})`,
        available: true,
        recommended: isRecommended,
        type: 'local',
        provider: 'ollama',
        description: `ë¡œì»¬ AI ëª¨ë¸ - ì™„ì „í•œ í”„ë¼ì´ë²„ì‹œ ë³´ì¥`,
        speed: modelName.includes(':1b') ? 'very-fast' :
               modelName.includes(':3b') ? 'fast' : 'moderate',
        privacy: 'local-processing-only',
        cueBonus: 'ë¡œì»¬ AI ì‚¬ìš© ì‹œ í”„ë¼ì´ë²„ì‹œ ë³´ë„ˆìŠ¤ +5 CUE'
      };
    });

    res.json({
      success: true,
      connected: true,
      provider: 'ollama',
      serverUrl: 'http://localhost:11434',
      privacy: '100% ë¡œì»¬ ì²˜ë¦¬ - ë°ì´í„° ì™¸ë¶€ ì „ì†¡ ì—†ìŒ',
      models: modelList,
      totalModels: modelList.length,
      recommendations: {
        beginners: 'llama3.2:1b - ë¹ ë¥´ê³  ê°€ë²¼ì›€',
        balanced: 'llama3.2:3b - ì„±ëŠ¥ê³¼ ì†ë„ì˜ ê· í˜•',
        advanced: 'gemma2:2b - Google ê¸°ìˆ  ê¸°ë°˜'
      },
      benefits: [
        'ğŸ”’ ì™„ì „í•œ í”„ë¼ì´ë²„ì‹œ ë³´ì¥',
        'âš¡ ë¹ ë¥¸ ë¡œì»¬ ì²˜ë¦¬',
        'ğŸŒ ì˜¤í”„ë¼ì¸ ë™ì‘ ê°€ëŠ¥',
        'ğŸ’ í”„ë¼ì´ë²„ì‹œ ë³´ë„ˆìŠ¤ CUE',
        'ğŸ“± ì¸í„°ë„· ì—°ê²° ë¶ˆí•„ìš”'
      ],
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    console.error('âŒ Ollama ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜:', error);
    res.status(500).json({
      success: false,
      error: 'Failed to retrieve Ollama models',
      message: 'Ollama ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤',
      models: [],
      provider: 'ollama'
    });
  }
});

// ============================================================================
// ğŸ”½ Ollama ëª¨ë¸ ë‹¤ìš´ë¡œë“œ API
// ============================================================================

router.post('/models/pull', async (req: Request, res: Response): Promise<void> => {
  const { model } = req.body;
  
  if (!model) {
    res.status(400).json({
      success: false,
      error: 'Model name is required',
      message: 'ëª¨ë¸ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”',
      examples: ['llama3.2:3b', 'llama3.2:1b', 'gemma2:2b']
    });
    return;
  }

  try {
    console.log(`ğŸ”½ Ollama ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘: ${model}`);
    
    const ollamaService = getOllamaService();
    await ollamaService.pullModel(model);
    
    res.json({
      success: true,
      message: `ëª¨ë¸ ${model} ë‹¤ìš´ë¡œë“œê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤`,
      model: model,
      provider: 'ollama',
      note: 'ë‹¤ìš´ë¡œë“œ ì™„ë£Œê¹Œì§€ ëª‡ ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤',
      checkCommand: `ollama list`,
      timestamp: new Date().toISOString()
    });
    
  } catch (error: any) {
    console.error(`âŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: ${model}`, error);
    res.status(500).json({
      success: false,
      error: `ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: ${error.message}`,
      model: model,
      suggestion: 'Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”',
      troubleshooting: [
        'ollama serve ëª…ë ¹ì–´ë¡œ ì„œë²„ ì‹œì‘',
        'ì¸í„°ë„· ì—°ê²° ìƒíƒœ í™•ì¸',
        'ì¶©ë¶„í•œ ë””ìŠ¤í¬ ê³µê°„ í™•ì¸'
      ]
    });
  }
});

// ============================================================================
// ğŸ“Š Ollama ì„œë²„ ìƒíƒœ API
// ============================================================================

router.get('/status', async (req: Request, res: Response): Promise<void> => {
  try {
    console.log('ğŸ“Š === Ollama ì„œë²„ ìƒíƒœ í™•ì¸ ===');
    
    const ollamaService = getOllamaService();
    
    const isConnected = await ollamaService.checkConnection();
    const models = isConnected ? await ollamaService.getModels() : [];
    
    res.json({
      success: true,
      ollama: {
        connected: isConnected,
        serverUrl: process.env.OLLAMA_URL || 'http://localhost:11434',
        models: models,
        modelCount: models.length,
        status: isConnected ? 'healthy' : 'disconnected'
      },
      system: {
        provider: 'ollama',
        privacy: 'local-processing-only',
        internetRequired: false,
        dataRetention: 'local-only',
        uptime: process.uptime(),
        nodeVersion: process.version
      },
      features: {
        localAI: true,
        privacyGuaranteed: true,
        offlineCapable: true,
        cueRewards: true,
        modelDownloads: true
      },
      recommendations: isConnected ? 
        models.length > 0 ? 
          'âœ… Ollamaê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤!' :
          'âš ï¸ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•´ì£¼ì„¸ìš”: ollama pull llama3.2:3b' :
        'âŒ Ollama ì„œë²„ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”: ollama serve',
      timestamp: new Date().toISOString()
    });
    
  } catch (error: any) {
    console.error('âŒ Ollama ìƒíƒœ í™•ì¸ ì˜¤ë¥˜:', error);
    
    res.json({
      success: false,
      ollama: {
        connected: false,
        error: error.message,
        status: 'error'
      },
      system: {
        provider: 'ollama',
        privacy: 'local-processing-only'
      },
      troubleshooting: [
        '1. Ollama ì„¤ì¹˜: brew install ollama',
        '2. ì„œë²„ ì‹œì‘: ollama serve',
        '3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: ollama pull llama3.2:3b',
        '4. ì—°ê²° í™•ì¸: curl http://localhost:11434'
      ],
      timestamp: new Date().toISOString()
    });
  }
});

// ============================================================================
// ğŸ¥ í—¬ìŠ¤ì²´í¬ API
// ============================================================================

router.get('/health', (req: Request, res: Response): void => {
  res.json({
    success: true,
    service: 'Ollama ì „ìš© AI Routes',
    version: '1.0.0-ollama-only',
    provider: 'ollama',
    privacy: 'local-processing-only',
    features: [
      'ğŸ¦™ Ollama ë¡œì»¬ AI ì „ìš©',
      'ğŸ”’ 100% í”„ë¼ì´ë²„ì‹œ ë³´ì¥',
      'âš¡ ë¹ ë¥¸ ë¡œì»¬ ì²˜ë¦¬',
      'ğŸŒ ì˜¤í”„ë¼ì¸ ë™ì‘ ê°€ëŠ¥',
      'ğŸ’ í”„ë¼ì´ë²„ì‹œ ë³´ë„ˆìŠ¤ CUE',
      'ğŸš« í´ë¼ìš°ë“œ AI ì™„ì „ ì œê±°'
    ],
    endpoints: [
      'POST /chat - Ollama AI ì±„íŒ…',
      'GET /models - ëª¨ë¸ ëª©ë¡',
      'POST /models/pull - ëª¨ë¸ ë‹¤ìš´ë¡œë“œ',
      'GET /status - ì„œë²„ ìƒíƒœ',
      'GET /health - í—¬ìŠ¤ì²´í¬'
    ],
    requirements: {
      ollama: 'https://ollama.ai',
      models: ['llama3.2:3b', 'llama3.2:1b', 'gemma2:2b'],
      server: 'ollama serve (http://localhost:11434)'
    },
    timestamp: new Date().toISOString()
  });
});

console.log('âœ… ìˆœìˆ˜ Ollama ì „ìš© AI Routes ë¡œë”© ì™„ë£Œ');
console.log('ğŸ”’ í´ë¼ìš°ë“œ AI ì™„ì „ ì œê±° - 100% ë¡œì»¬ í”„ë¼ì´ë²„ì‹œ ë³´ì¥');

export default router;
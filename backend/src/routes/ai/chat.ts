// ============================================================================
// ğŸ“ backend/src/routes/ai/chat.ts
// ğŸ¤– AI ì±„íŒ… ë¼ìš°í„° - DI íŒ¨í„´ ì ìš© (ëŒ€í­ ê°„ì†Œí™”)
// ============================================================================

import { Router, Request, Response } from 'express';
import { getService } from '../../core/DIContainer';
import { authMiddleware } from '../../middleware/authMiddleware';

const router = Router();

// DIì—ì„œ ì„œë¹„ìŠ¤ ê°€ì ¸ì˜¤ê¸°
const getAIService = () => getService('AIService');
const getPersonalizationService = () => getService('PersonalizationService');
const getCueService = () => getService('CueService');
const getPersonalCueExtractor = () => getService('PersonalCueExtractor');
const getSemanticCompressionService = () => getService('SemanticCompressionService');

// ============================================================================
// ğŸ¤– AI ì±„íŒ… API (ì¸ì¦ í•„ìš”)
// ============================================================================

router.post('/chat', authMiddleware, async (req: Request, res: Response): Promise<void> => {
  console.log('ğŸ¤– === AI ì±„íŒ… ìš”ì²­ ===');
  
  try {
    const { 
      message, 
      model = 'gpt-4', 
      includeContext = true,
      temperature = 0.7,
      maxTokens = 1000
    } = req.body;
    
    const user = (req as any).user;
    
    if (!message || message.trim().length === 0) {
      res.status(400).json({
        success: false,
        error: 'ë©”ì‹œì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤'
      });
      return;
    }
    
    console.log(`ğŸ“ ì‚¬ìš©ì: ${user.username || user.id}, ëª¨ë¸: ${model}`);
    
    // DI ì„œë¹„ìŠ¤ë“¤ ì‚¬ìš©
    const aiService = getAIService();
    const personalizationService = getPersonalizationService();
    const cueService = getCueService();
    const cueExtractor = getPersonalCueExtractor();
    
    // ê°œì¸í™” ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    let personalizationContext = null;
    if (includeContext) {
      personalizationContext = await personalizationService.getPersonalizationContext(user.did);
      console.log(`ğŸ§  ê°œì¸í™” ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ: ${personalizationContext?.cues?.length || 0}ê°œ ë‹¨ì„œ`);
    }
    
    // AI ì‘ë‹µ ìƒì„±
    const startTime = Date.now();
    const aiResponse = await aiService.generateResponse(
      message,
      model,
      personalizationContext,
      user.did,
      { temperature, maxTokens }
    );
    const processingTime = Date.now() - startTime;
    
    console.log(`âœ… AI ì‘ë‹µ ìƒì„± ì™„ë£Œ (${processingTime}ms)`);
    
    // ëŒ€í™”ì—ì„œ ê°œì¸ ë‹¨ì„œ ì¶”ì¶œ (ë°±ê·¸ë¼ìš´ë“œ)
    try {
      const conversationData = {
        userMessage: message,
        aiResponse: aiResponse.content,
        timestamp: new Date().toISOString(),
        model,
        context: personalizationContext
      };
      
      const extractedCues = await cueExtractor.extractFromConversation(conversationData, user.did);
      console.log(`ğŸ” ìƒˆë¡œìš´ ê°œì¸ ë‹¨ì„œ ì¶”ì¶œ: ${extractedCues.length}ê°œ`);
      
      // CUE í† í° ì§€ê¸‰ (í’ˆì§ˆ ê¸°ë°˜)
      const baseReward = 5;
      const qualityBonus = Math.floor(aiResponse.qualityScore * 10);
      const contextBonus = personalizationContext ? 3 : 0;
      const totalReward = baseReward + qualityBonus + contextBonus;
      
      await cueService.awardTokens(user.did, totalReward, 'ai_chat', {
        messageLength: message.length,
        responseLength: aiResponse.content.length,
        qualityScore: aiResponse.qualityScore,
        usedContext: !!personalizationContext,
        extractedCues: extractedCues.length
      });
      
      console.log(`ğŸ’° CUE í† í° ì§€ê¸‰: ${totalReward}ê°œ (í’ˆì§ˆ: ${qualityBonus}, ì»¨í…ìŠ¤íŠ¸: ${contextBonus})`);
      
    } catch (cueError) {
      console.warn('âš ï¸ ê°œì¸ ë‹¨ì„œ ì¶”ì¶œ ì‹¤íŒ¨:', cueError);
    }
    
    // ì‘ë‹µ ë°˜í™˜
    res.json({
      success: true,
      response: aiResponse.content,
      model: aiResponse.model,
      provider: aiResponse.provider,
      personalizationLevel: aiResponse.personalizationLevel,
      qualityScore: aiResponse.qualityScore,
      usedData: aiResponse.usedData,
      cueReward: baseReward + qualityBonus + contextBonus,
      tokensUsed: aiResponse.tokensUsed,
      processingTime,
      timestamp: new Date().toISOString()
    });
    
  } catch (error) {
    console.error('ğŸ’¥ AI ì±„íŒ… ì˜¤ë¥˜:', error);
    res.status(500).json({
      success: false,
      error: 'AI chat failed',
      message: error.message,
      timestamp: new Date().toISOString()
    });
  }
});

// ============================================================================
// ğŸ¯ AI ëª¨ë¸ ê´€ë¦¬ API
// ============================================================================

router.get('/models', async (req: Request, res: Response): Promise<void> => {
  try {
    console.log('ğŸ“‹ === AI ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ===');
    
    // DI ì„œë¹„ìŠ¤ ì‚¬ìš©
    const aiService = getAIService();
    const models = await aiService.getAvailableModels();
    
    res.json({
      success: true,
      models: models.map(model => ({
        id: model.id,
        name: model.name,
        provider: model.provider,
        type: model.type,
        available: model.available,
        recommended: model.recommended || false,
        description: model.description,
        maxTokens: model.maxTokens,
        contextWindow: model.contextWindow
      })),
      totalModels: models.length,
      availableModels: models.filter(m => m.available).length,
      timestamp: new Date().toISOString()
    });
    
  } catch (error) {
    console.error('ğŸ’¥ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜:', error);
    res.status(500).json({
      success: false,
      error: 'Failed to get models',
      message: error.message
    });
  }
});

// ëª¨ë¸ ìƒíƒœ í™•ì¸
router.get('/models/:modelId/status', async (req: Request, res: Response): Promise<void> => {
  try {
    const { modelId } = req.params;
    
    // DI ì„œë¹„ìŠ¤ ì‚¬ìš©
    const aiService = getAIService();
    const status = await aiService.getModelStatus(modelId);
    
    res.json({
      success: true,
      modelId,
      status,
      timestamp: new Date().toISOString()
    });
    
  } catch (error) {
    console.error('ğŸ’¥ ëª¨ë¸ ìƒíƒœ í™•ì¸ ì˜¤ë¥˜:', error);
    res.status(500).json({
      success: false,
      error: 'Failed to get model status',
      message: error.message
    });
  }
});

// ============================================================================
// ğŸ§  ê°œì¸í™” ê´€ë¦¬ API
// ============================================================================

router.get('/personalization/profile', authMiddleware, async (req: Request, res: Response): Promise<void> => {
  try {
    const user = (req as any).user;
    console.log(`ğŸ§  === ê°œì¸í™” í”„ë¡œí•„ ì¡°íšŒ: ${user.did} ===`);
    
    // DI ì„œë¹„ìŠ¤ ì‚¬ìš©
    const personalizationService = getPersonalizationService();
    const profile = await personalizationService.getPersonalityProfile(user.did);
    
    res.json({
      success: true,
      profile,
      timestamp: new Date().toISOString()
    });
    
  } catch (error) {
    console.error('ğŸ’¥ ê°œì¸í™” í”„ë¡œí•„ ì¡°íšŒ ì˜¤ë¥˜:', error);
    res.status(500).json({
      success: false,
      error: 'Failed to get personalization profile',
      message: error.message
    });
  }
});

router.get('/personalization/context', authMiddleware, async (req: Request, res: Response): Promise<void> => {
  try {
    const user = (req as any).user;
    console.log(`ğŸ§  === ê°œì¸í™” ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ: ${user.did} ===`);
    
    // DI ì„œë¹„ìŠ¤ ì‚¬ìš©
    const personalizationService = getPersonalizationService();
    const context = await personalizationService.getPersonalizationContext(user.did);
    
    res.json({
      success: true,
      context: {
        personalityProfile: context?.personalityProfile,
        cuesCount: context?.cues?.length || 0,
        vaultCount: context?.vaultIds?.length || 0,
        personalityMatch: context?.personalityMatch || 0,
        behaviorPatterns: context?.behaviorPatterns || [],
        preferences: context?.preferences || {}
      },
      timestamp: new Date().toISOString()
    });
    
  } catch (error) {
    console.error('ğŸ’¥ ê°œì¸í™” ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ ì˜¤ë¥˜:', error);
    res.status(500).json({
      success: false,
      error: 'Failed to get personalization context',
      message: error.message
    });
  }
});

// ============================================================================
// ğŸ”§ ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ API
// ============================================================================

router.get('/history', authMiddleware, async (req: Request, res: Response): Promise<void> => {
  try {
    const user = (req as any).user;
    const { page = 1, limit = 20 } = req.query;
    
    console.log(`ğŸ“– === ëŒ€í™” ê¸°ë¡ ì¡°íšŒ: ${user.did} ===`);
    
    // DI ì„œë¹„ìŠ¤ ì‚¬ìš©
    const aiService = getAIService();
    const history = await aiService.getChatHistory(user.did, {
      page: parseInt(page as string),
      limit: parseInt(limit as string)
    });
    
    res.json({
      success: true,
      history,
      pagination: {
        page: parseInt(page as string),
        limit: parseInt(limit as string),
        total: history.length
      },
      timestamp: new Date().toISOString()
    });
    
  } catch (error) {
    console.error('ğŸ’¥ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ ì˜¤ë¥˜:', error);
    res.status(500).json({
      success: false,
      error: 'Failed to get chat history',
      message: error.message
    });
  }
});

// ============================================================================
// ğŸ” ì‹œìŠ¤í…œ ìƒíƒœ API
// ============================================================================

router.get('/status', async (req: Request, res: Response): Promise<void> => {
  try {
    console.log('ğŸ” === AI ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ===');
    
    // DI ì„œë¹„ìŠ¤ë“¤ ìƒíƒœ í™•ì¸
    const aiService = getAIService();
    const personalizationService = getPersonalizationService();
    const cueService = getCueService();
    
    const status = {
      ai: await aiService.getStatus(),
      personalization: await personalizationService.getStatus(),
      cue: await cueService.getStatus(),
      features: {
        aiChat: true,
        personalization: true,
        cueRewards: true,
        multiModel: true,
        contextLearning: true
      },
      timestamp: new Date().toISOString()
    };
    
    res.json({
      success: true,
      status,
      message: 'AI ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤'
    });
    
  } catch (error) {
    console.error('ğŸ’¥ AI ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì˜¤ë¥˜:', error);
    res.status(500).json({
      success: false,
      error: 'Failed to get AI system status',
      message: error.message
    });
  }
});

// ì‚¬ìš© ê°€ì´ë“œ
router.get('/guide', (req: Request, res: Response): void => {
  res.json({
    success: true,
    service: 'AI ì±„íŒ… ì„œë¹„ìŠ¤',
    version: '3.0 (DI ì ìš©)',
    
    features: {
      core: [
        'âœ… ë©€í‹° ëª¨ë¸ ì§€ì› (GPT-4, Claude, Ollama)',
        'âœ… ê°œì¸í™” ì»¨í…ìŠ¤íŠ¸ í•™ìŠµ',
        'âœ… ì‹¤ì‹œê°„ CUE í† í° ë§ˆì´ë‹',
        'âœ… í’ˆì§ˆ ê¸°ë°˜ ë³´ìƒ ì‹œìŠ¤í…œ',
        'âœ… ëŒ€í™” ê¸°ë¡ ê´€ë¦¬'
      ],
      personalization: [
        'ğŸ§  ê°œì¸ ì„±ê²© í”„ë¡œí•„ í•™ìŠµ',
        'ğŸ§  ëŒ€í™” íŒ¨í„´ ë¶„ì„',
        'ğŸ§  ì„ í˜¸ë„ í•™ìŠµ ë° ì ìš©',
        'ğŸ§  ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‘ë‹µ ìƒì„±'
      ],
      mining: [
        'ğŸ’° ëŒ€í™” ì°¸ì—¬ ê¸°ë³¸ ë³´ìƒ',
        'ğŸ’° ì‘ë‹µ í’ˆì§ˆ ê¸°ë°˜ ë³´ë„ˆìŠ¤',
        'ğŸ’° ê°œì¸í™” ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš© ë³´ë„ˆìŠ¤',
        'ğŸ’° ê°œì¸ ë‹¨ì„œ ì¶”ì¶œ ë³´ë„ˆìŠ¤'
      ]
    },
    
    endpoints: {
      chat: {
        'POST /chat': 'AI ì±„íŒ… (ì¸ì¦ í•„ìš”)',
        'GET /models': 'ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡',
        'GET /models/:id/status': 'íŠ¹ì • ëª¨ë¸ ìƒíƒœ',
        'GET /history': 'ëŒ€í™” ê¸°ë¡ ì¡°íšŒ'
      },
      personalization: {
        'GET /personalization/profile': 'ê°œì¸í™” í”„ë¡œí•„',
        'GET /personalization/context': 'ê°œì¸í™” ì»¨í…ìŠ¤íŠ¸'
      },
      system: {
        'GET /status': 'ì‹œìŠ¤í…œ ìƒíƒœ',
        'GET /guide': 'ì´ ê°€ì´ë“œ'
      }
    },
    
    usage: {
      basicChat: {
        method: 'POST',
        endpoint: '/chat',
        headers: { 'Authorization': 'Bearer YOUR_SESSION_TOKEN' },
        body: {
          message: 'ì•ˆë…•í•˜ì„¸ìš”',
          model: 'gpt-4',
          includeContext: true
        }
      },
      advancedChat: {
        method: 'POST',
        endpoint: '/chat',
        body: {
          message: 'ë³µì¡í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤',
          model: 'claude-3',
          includeContext: true,
          temperature: 0.8,
          maxTokens: 2000
        }
      }
    },
    
    rewards: {
      base: '5 CUE (ê¸°ë³¸ ëŒ€í™” ì°¸ì—¬)',
      quality: '0-10 CUE (ì‘ë‹µ í’ˆì§ˆ ê¸°ë°˜)',
      context: '3 CUE (ê°œì¸í™” ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©)',
      extraction: '1-5 CUE (ìƒˆë¡œìš´ ê°œì¸ ë‹¨ì„œ ì¶”ì¶œ)'
    },
    
    note: 'DI ì ìš©ìœ¼ë¡œ ë³µì¡í•œ AI ë¡œì§ì´ ì„œë¹„ìŠ¤ ê³„ì¸µìœ¼ë¡œ ë¶„ë¦¬ë˜ì–´ ì½”ë“œê°€ í›¨ì”¬ ê°„ê²°í•´ì¡ŒìŠµë‹ˆë‹¤.'
  });
});

console.log('âœ… AI Chat routes initialized with DI');
export default router;